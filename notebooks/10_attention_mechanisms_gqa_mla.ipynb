{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Attention Mechanisms: GQA, MLA, and KV Cache\n",
    "\n",
    "This notebook explores modern attention mechanisms and optimization techniques for efficient LLM inference.\n",
    "\n",
    "We'll cover:\n",
    "1. **Multi-Head Attention (MHA)** - Baseline\n",
    "2. **Multi-Query Attention (MQA)** - Single K/V head\n",
    "3. **Grouped Query Attention (GQA)** - Middle ground (used in LLaMA 2)\n",
    "4. **Multi-Head Latent Attention (MLA)** - Low-rank compression\n",
    "5. **KV Cache** - Critical for autoregressive inference\n",
    "6. **Performance comparisons**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Standard Multi-Head Attention (MHA)\n",
    "\n",
    "Traditional MHA has **separate Q, K, V heads for each attention head**:\n",
    "- H heads, each with separate Q, K, V projections\n",
    "- Memory: O(H × d)\n",
    "- Used in: Original Transformer, GPT-2, GPT-3\n",
    "\n",
    "$$\\text{MHA}(Q, K, V) = \\text{Concat}(\\text{head}_1, ..., \\text{head}_H)W^O$$\n",
    "$$\\text{head}_i = \\text{Attention}(QW^Q_i, KW^K_i, VW^V_i)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MHA - Input: torch.Size([2, 10, 512])\n",
      "MHA - Output: torch.Size([2, 10, 512])\n",
      "MHA - Attention: torch.Size([2, 8, 10, 10])\n",
      "MHA - Parameters: 1,050,624\n",
      "MHA - Cache K shape: torch.Size([2, 10, 8, 64]), Cache V shape: torch.Size([2, 10, 8, 64])\n"
     ]
    }
   ],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Standard Multi-Head Attention (MHA).\n",
    "    Each head has its own Q, K, V projections.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, num_heads, dropout=0.1):\n",
    "        super().__init__()\n",
    "        assert d_model % num_heads == 0\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_model // num_heads\n",
    "        \n",
    "        # Separate projections for Q, K, V\n",
    "        self.q_proj = nn.Linear(d_model, d_model)\n",
    "        self.k_proj = nn.Linear(d_model, d_model)\n",
    "        self.v_proj = nn.Linear(d_model, d_model)\n",
    "        self.out_proj = nn.Linear(d_model, d_model)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.scale = math.sqrt(self.head_dim)\n",
    "    \n",
    "    def forward(self, x, mask=None, kv_cache=None, use_cache=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Input (batch_size, seq_len, d_model)\n",
    "            mask: Attention mask\n",
    "            kv_cache: Cached K, V from previous steps\n",
    "            use_cache: Whether to return cache for next step\n",
    "        \"\"\"\n",
    "        batch_size, seq_len, _ = x.shape\n",
    "        \n",
    "        # Project to Q, K, V\n",
    "        q = self.q_proj(x)\n",
    "        k = self.k_proj(x)\n",
    "        v = self.v_proj(x)\n",
    "        \n",
    "        # Reshape for multi-head: (batch, seq_len, num_heads, head_dim)\n",
    "        q = q.view(batch_size, seq_len, self.num_heads, self.head_dim)\n",
    "        k = k.view(batch_size, seq_len, self.num_heads, self.head_dim)\n",
    "        v = v.view(batch_size, seq_len, self.num_heads, self.head_dim)\n",
    "        \n",
    "        # Handle KV cache for autoregressive generation\n",
    "        if kv_cache is not None:\n",
    "            past_k, past_v = kv_cache\n",
    "            k = torch.cat([past_k, k], dim=1)\n",
    "            v = torch.cat([past_v, v], dim=1)\n",
    "        \n",
    "        # Transpose for attention: (batch, num_heads, seq_len, head_dim)\n",
    "        q = q.transpose(1, 2)\n",
    "        k = k.transpose(1, 2)\n",
    "        v = v.transpose(1, 2)\n",
    "        \n",
    "        # Compute attention\n",
    "        scores = torch.matmul(q, k.transpose(-2, -1)) / self.scale\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, float('-inf'))\n",
    "        \n",
    "        attn_weights = F.softmax(scores, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "        \n",
    "        out = torch.matmul(attn_weights, v)\n",
    "        \n",
    "        # Reshape and project\n",
    "        out = out.transpose(1, 2).contiguous()\n",
    "        out = out.view(batch_size, seq_len, self.d_model)\n",
    "        out = self.out_proj(out)\n",
    "        \n",
    "        new_cache = (k.transpose(1, 2), v.transpose(1, 2)) if use_cache else None\n",
    "        return out, attn_weights, new_cache\n",
    "\n",
    "# Example\n",
    "mha = MultiHeadAttention(d_model=512, num_heads=8)\n",
    "x = torch.randn(2, 10, 512)\n",
    "out, attn, cache = mha(x, use_cache=True)\n",
    "\n",
    "print(f\"MHA - Input: {x.shape}\")\n",
    "print(f\"MHA - Output: {out.shape}\")\n",
    "print(f\"MHA - Attention: {attn.shape}\")\n",
    "print(f\"MHA - Parameters: {sum(p.numel() for p in mha.parameters()):,}\")\n",
    "if cache:\n",
    "    print(f\"MHA - Cache K shape: {cache[0].shape}, Cache V shape: {cache[1].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Multi-Query Attention (MQA)\n",
    "\n",
    "MQA uses **single shared K and V** across all heads:\n",
    "- H query heads, but only 1 K head and 1 V head\n",
    "- Memory: O(d) for K, V (much smaller!)\n",
    "- Used in: PaLM, Falcon\n",
    "\n",
    "**Key benefit:** Dramatically reduces KV cache size during inference\n",
    "\n",
    "**Trade-off:** Slightly lower quality than MHA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MQA - Input: torch.Size([2, 10, 512])\n",
      "MQA - Output: torch.Size([2, 10, 512])\n",
      "MQA - Attention: torch.Size([2, 8, 10, 10])\n",
      "MQA - Parameters: 590,976\n",
      "MQA - Cache K shape: torch.Size([2, 10, 64]), Cache V shape: torch.Size([2, 10, 64])\n",
      "MQA - Cache is 8x smaller than MHA!\n"
     ]
    }
   ],
   "source": [
    "class MultiQueryAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-Query Attention (MQA).\n",
    "    Multiple query heads, but single shared K and V.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, num_heads, dropout=0.1):\n",
    "        super().__init__()\n",
    "        assert d_model % num_heads == 0\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_model // num_heads\n",
    "        \n",
    "        # Multiple query heads\n",
    "        self.q_proj = nn.Linear(d_model, d_model)\n",
    "        \n",
    "        # Single K and V (shared across all heads)\n",
    "        self.k_proj = nn.Linear(d_model, self.head_dim)\n",
    "        self.v_proj = nn.Linear(d_model, self.head_dim)\n",
    "        \n",
    "        self.out_proj = nn.Linear(d_model, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.scale = math.sqrt(self.head_dim)\n",
    "    \n",
    "    def forward(self, x, mask=None, kv_cache=None, use_cache=False):\n",
    "        batch_size, seq_len, _ = x.shape\n",
    "        \n",
    "        # Project queries (multiple heads)\n",
    "        q = self.q_proj(x)\n",
    "        q = q.view(batch_size, seq_len, self.num_heads, self.head_dim)\n",
    "        \n",
    "        # Project K, V (single head, will be broadcast)\n",
    "        k = self.k_proj(x)  # (batch, seq_len, head_dim)\n",
    "        v = self.v_proj(x)  # (batch, seq_len, head_dim)\n",
    "        \n",
    "        # Handle KV cache\n",
    "        if kv_cache is not None:\n",
    "            past_k, past_v = kv_cache\n",
    "            k = torch.cat([past_k, k], dim=1)\n",
    "            v = torch.cat([past_v, v], dim=1)\n",
    "        \n",
    "        # Reshape for broadcasting\n",
    "        # Q: (batch, num_heads, seq_len, head_dim)\n",
    "        # K, V: (batch, 1, kv_seq_len, head_dim) - will broadcast across heads\n",
    "        q = q.transpose(1, 2)\n",
    "        k = k.unsqueeze(1)  # Add head dimension for broadcasting\n",
    "        v = v.unsqueeze(1)\n",
    "        \n",
    "        # Compute attention (K, V broadcast across all query heads)\n",
    "        scores = torch.matmul(q, k.transpose(-2, -1)) / self.scale\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, float('-inf'))\n",
    "        \n",
    "        attn_weights = F.softmax(scores, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "        \n",
    "        out = torch.matmul(attn_weights, v)\n",
    "        \n",
    "        # Reshape and project\n",
    "        out = out.transpose(1, 2).contiguous()\n",
    "        out = out.view(batch_size, seq_len, self.d_model)\n",
    "        out = self.out_proj(out)\n",
    "        \n",
    "        # Cache stores only single K, V (not per-head)\n",
    "        new_cache = (k.squeeze(1), v.squeeze(1)) if use_cache else None\n",
    "        return out, attn_weights, new_cache\n",
    "\n",
    "# Example\n",
    "mqa = MultiQueryAttention(d_model=512, num_heads=8)\n",
    "x = torch.randn(2, 10, 512)\n",
    "out, attn, cache = mqa(x, use_cache=True)\n",
    "\n",
    "print(f\"\\nMQA - Input: {x.shape}\")\n",
    "print(f\"MQA - Output: {out.shape}\")\n",
    "print(f\"MQA - Attention: {attn.shape}\")\n",
    "print(f\"MQA - Parameters: {sum(p.numel() for p in mqa.parameters()):,}\")\n",
    "if cache:\n",
    "    print(f\"MQA - Cache K shape: {cache[0].shape}, Cache V shape: {cache[1].shape}\")\n",
    "    print(f\"MQA - Cache is {mha.num_heads}x smaller than MHA!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Grouped Query Attention (GQA)\n",
    "\n",
    "GQA is the **middle ground between MHA and MQA**:\n",
    "- H query heads divided into G groups\n",
    "- Each group shares one K and V head\n",
    "- Memory: O(G × d) where G < H\n",
    "- Used in: **LLaMA 2, Mistral**\n",
    "\n",
    "**Benefits:**\n",
    "- Better quality than MQA (more K/V diversity)\n",
    "- Smaller cache than MHA\n",
    "- Good balance for production LLMs\n",
    "\n",
    "Example: 32 query heads → 8 KV groups (4 queries per KV head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GQA - Input: torch.Size([2, 10, 512])\n",
      "GQA - Output: torch.Size([2, 10, 512])\n",
      "GQA - Attention: torch.Size([2, 8, 10, 10])\n",
      "GQA - Parameters: 656,640\n",
      "GQA - Queries per KV: 4\n",
      "GQA - Cache K shape: torch.Size([2, 10, 2, 64]), Cache V shape: torch.Size([2, 10, 2, 64])\n",
      "GQA - Cache is 4x smaller than MHA!\n"
     ]
    }
   ],
   "source": [
    "class GroupedQueryAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Grouped Query Attention (GQA).\n",
    "    Query heads are divided into groups, each group shares K and V.\n",
    "    Used in LLaMA 2.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, num_heads, num_kv_heads, dropout=0.1):\n",
    "        super().__init__()\n",
    "        assert d_model % num_heads == 0\n",
    "        assert num_heads % num_kv_heads == 0, \"num_heads must be divisible by num_kv_heads\"\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.num_kv_heads = num_kv_heads\n",
    "        self.head_dim = d_model // num_heads\n",
    "        self.num_queries_per_kv = num_heads // num_kv_heads\n",
    "        \n",
    "        # Query projection (all heads)\n",
    "        self.q_proj = nn.Linear(d_model, d_model)\n",
    "        \n",
    "        # K, V projections (num_kv_heads)\n",
    "        self.k_proj = nn.Linear(d_model, num_kv_heads * self.head_dim)\n",
    "        self.v_proj = nn.Linear(d_model, num_kv_heads * self.head_dim)\n",
    "        \n",
    "        self.out_proj = nn.Linear(d_model, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.scale = math.sqrt(self.head_dim)\n",
    "    \n",
    "    def forward(self, x, mask=None, kv_cache=None, use_cache=False):\n",
    "        batch_size, seq_len, _ = x.shape\n",
    "        \n",
    "        # Project Q (all heads)\n",
    "        q = self.q_proj(x)\n",
    "        q = q.view(batch_size, seq_len, self.num_heads, self.head_dim)\n",
    "        \n",
    "        # Project K, V (num_kv_heads)\n",
    "        k = self.k_proj(x)\n",
    "        v = self.v_proj(x)\n",
    "        k = k.view(batch_size, seq_len, self.num_kv_heads, self.head_dim)\n",
    "        v = v.view(batch_size, seq_len, self.num_kv_heads, self.head_dim)\n",
    "        \n",
    "        # Handle KV cache\n",
    "        if kv_cache is not None:\n",
    "            past_k, past_v = kv_cache\n",
    "            k = torch.cat([past_k, k], dim=1)\n",
    "            v = torch.cat([past_v, v], dim=1)\n",
    "        \n",
    "        # Transpose: (batch, num_heads, seq_len, head_dim)\n",
    "        q = q.transpose(1, 2)\n",
    "        k = k.transpose(1, 2)\n",
    "        v = v.transpose(1, 2)\n",
    "        \n",
    "        # Repeat K, V for each group\n",
    "        # Shape: (batch, num_heads, seq_len, head_dim)\n",
    "        k = k.repeat_interleave(self.num_queries_per_kv, dim=1)\n",
    "        v = v.repeat_interleave(self.num_queries_per_kv, dim=1)\n",
    "        \n",
    "        # Compute attention\n",
    "        scores = torch.matmul(q, k.transpose(-2, -1)) / self.scale\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, float('-inf'))\n",
    "        \n",
    "        attn_weights = F.softmax(scores, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "        \n",
    "        out = torch.matmul(attn_weights, v)\n",
    "        \n",
    "        # Reshape and project\n",
    "        out = out.transpose(1, 2).contiguous()\n",
    "        out = out.view(batch_size, seq_len, self.d_model)\n",
    "        out = self.out_proj(out)\n",
    "        \n",
    "        # Cache stores only num_kv_heads (not all num_heads)\n",
    "        if use_cache:\n",
    "            k_cache = k[:, ::self.num_queries_per_kv, :, :].transpose(1, 2)\n",
    "            v_cache = v[:, ::self.num_queries_per_kv, :, :].transpose(1, 2)\n",
    "            new_cache = (k_cache, v_cache)\n",
    "        else:\n",
    "            new_cache = None\n",
    "        \n",
    "        return out, attn_weights, new_cache\n",
    "\n",
    "# Example: 8 heads with 2 KV heads (4 queries per KV)\n",
    "gqa = GroupedQueryAttention(d_model=512, num_heads=8, num_kv_heads=2)\n",
    "x = torch.randn(2, 10, 512)\n",
    "out, attn, cache = gqa(x, use_cache=True)\n",
    "\n",
    "print(f\"\\nGQA - Input: {x.shape}\")\n",
    "print(f\"GQA - Output: {out.shape}\")\n",
    "print(f\"GQA - Attention: {attn.shape}\")\n",
    "print(f\"GQA - Parameters: {sum(p.numel() for p in gqa.parameters()):,}\")\n",
    "print(f\"GQA - Queries per KV: {gqa.num_queries_per_kv}\")\n",
    "if cache:\n",
    "    print(f\"GQA - Cache K shape: {cache[0].shape}, Cache V shape: {cache[1].shape}\")\n",
    "    print(f\"GQA - Cache is {mha.num_heads // gqa.num_kv_heads}x smaller than MHA!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Multi-Head Latent Attention (MLA)\n",
    "\n",
    "MLA uses **low-rank compression** of K and V:\n",
    "- Projects K, V to lower-dimensional latent space\n",
    "- Stores compressed representation\n",
    "- Decompresses for attention computation\n",
    "- Used in: DeepSeek-V2\n",
    "\n",
    "**Key innovation:**\n",
    "- KV cache size reduced by ~90%\n",
    "- Compression ratio configurable\n",
    "- Minimal quality loss with proper tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MLA - Input: torch.Size([2, 10, 512])\n",
      "MLA - Output: torch.Size([2, 10, 512])\n",
      "MLA - Attention: torch.Size([2, 8, 10, 10])\n",
      "MLA - Parameters: 723,072\n",
      "MLA - Latent dimension: 128 (compression: 4.0x)\n",
      "MLA - Cache shape: torch.Size([2, 10, 128])\n",
      "MLA - Cache is ~4.0x smaller than MHA per element!\n"
     ]
    }
   ],
   "source": [
    "class MultiHeadLatentAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-Head Latent Attention (MLA).\n",
    "    Compresses K, V into low-rank latent representation.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, num_heads, latent_dim=None, dropout=0.1):\n",
    "        super().__init__()\n",
    "        assert d_model % num_heads == 0\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_model // num_heads\n",
    "        \n",
    "        # Latent dimension (compressed representation)\n",
    "        # Typically much smaller than d_model\n",
    "        self.latent_dim = latent_dim or (d_model // 4)\n",
    "        \n",
    "        # Query projection (full dimension)\n",
    "        self.q_proj = nn.Linear(d_model, d_model)\n",
    "        \n",
    "        # Compress to latent space\n",
    "        self.kv_compress = nn.Linear(d_model, self.latent_dim)\n",
    "        \n",
    "        # Decompress from latent to K, V\n",
    "        self.k_decompress = nn.Linear(self.latent_dim, d_model)\n",
    "        self.v_decompress = nn.Linear(self.latent_dim, d_model)\n",
    "        \n",
    "        self.out_proj = nn.Linear(d_model, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.scale = math.sqrt(self.head_dim)\n",
    "    \n",
    "    def forward(self, x, mask=None, kv_cache=None, use_cache=False):\n",
    "        batch_size, seq_len, _ = x.shape\n",
    "        \n",
    "        # Query projection (full dimension)\n",
    "        q = self.q_proj(x)\n",
    "        q = q.view(batch_size, seq_len, self.num_heads, self.head_dim)\n",
    "        \n",
    "        # Compress to latent space\n",
    "        kv_latent = self.kv_compress(x)  # (batch, seq_len, latent_dim)\n",
    "        \n",
    "        # Handle KV cache (cache stores compressed latent!)\n",
    "        if kv_cache is not None:\n",
    "            past_latent = kv_cache\n",
    "            kv_latent = torch.cat([past_latent, kv_latent], dim=1)\n",
    "        \n",
    "        # Decompress to K, V\n",
    "        k = self.k_decompress(kv_latent)\n",
    "        v = self.v_decompress(kv_latent)\n",
    "        \n",
    "        k = k.view(batch_size, -1, self.num_heads, self.head_dim)\n",
    "        v = v.view(batch_size, -1, self.num_heads, self.head_dim)\n",
    "        \n",
    "        # Transpose for attention\n",
    "        q = q.transpose(1, 2)\n",
    "        k = k.transpose(1, 2)\n",
    "        v = v.transpose(1, 2)\n",
    "        \n",
    "        # Compute attention\n",
    "        scores = torch.matmul(q, k.transpose(-2, -1)) / self.scale\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, float('-inf'))\n",
    "        \n",
    "        attn_weights = F.softmax(scores, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "        \n",
    "        out = torch.matmul(attn_weights, v)\n",
    "        \n",
    "        # Reshape and project\n",
    "        out = out.transpose(1, 2).contiguous()\n",
    "        out = out.view(batch_size, seq_len, self.d_model)\n",
    "        out = self.out_proj(out)\n",
    "        \n",
    "        # Cache stores compressed latent (much smaller!)\n",
    "        new_cache = kv_latent if use_cache else None\n",
    "        return out, attn_weights, new_cache\n",
    "\n",
    "# Example: latent_dim = d_model // 4 (4x compression)\n",
    "mla = MultiHeadLatentAttention(d_model=512, num_heads=8, latent_dim=128)\n",
    "x = torch.randn(2, 10, 512)\n",
    "out, attn, cache = mla(x, use_cache=True)\n",
    "\n",
    "print(f\"\\nMLA - Input: {x.shape}\")\n",
    "print(f\"MLA - Output: {out.shape}\")\n",
    "print(f\"MLA - Attention: {attn.shape}\")\n",
    "print(f\"MLA - Parameters: {sum(p.numel() for p in mla.parameters()):,}\")\n",
    "print(f\"MLA - Latent dimension: {mla.latent_dim} (compression: {mla.d_model / mla.latent_dim:.1f}x)\")\n",
    "if cache is not None:\n",
    "    print(f\"MLA - Cache shape: {cache.shape}\")\n",
    "    print(f\"MLA - Cache is ~{mla.d_model / mla.latent_dim:.1f}x smaller than MHA per element!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. KV Cache Visualization and Analysis\n",
    "\n",
    "The KV cache is crucial for efficient autoregressive generation:\n",
    "- Store K, V from previous tokens\n",
    "- Reuse for each new token\n",
    "- Avoid recomputing attention for entire sequence\n",
    "\n",
    "**Without KV cache:** O(n²) for n tokens\n",
    "**With KV cache:** O(n) for n tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Autoregressive Generation with KV Cache ===\n",
      "\n",
      "Step 1: Process prompt (length 5)\n",
      "  Cache K shape: torch.Size([1, 5, 8, 32])\n",
      "  Cache V shape: torch.Size([1, 5, 8, 32])\n",
      "  Total cache size: 2560 elements\n",
      "\n",
      "Step 2: Generate token 1\n",
      "  Input: torch.Size([1, 1, 256])\n",
      "  Cache K shape: torch.Size([1, 6, 8, 32]) (grew by 1)\n",
      "  Cache V shape: torch.Size([1, 6, 8, 32]) (grew by 1)\n",
      "\n",
      "Step 3: Generate token 2\n",
      "  Input: torch.Size([1, 1, 256])\n",
      "  Cache K shape: torch.Size([1, 7, 8, 32]) (grew by 1)\n",
      "  Cache V shape: torch.Size([1, 7, 8, 32]) (grew by 1)\n",
      "\n",
      "Step 4: Generate token 3\n",
      "  Input: torch.Size([1, 1, 256])\n",
      "  Cache K shape: torch.Size([1, 8, 8, 32]) (grew by 1)\n",
      "  Cache V shape: torch.Size([1, 8, 8, 32]) (grew by 1)\n",
      "\n",
      "Final sequence length: 8\n",
      "Final cache size: torch.Size([1, 8, 8, 32])\n"
     ]
    }
   ],
   "source": [
    "def demonstrate_kv_cache():\n",
    "    \"\"\"\n",
    "    Demonstrate KV cache usage in autoregressive generation.\n",
    "    \"\"\"\n",
    "    d_model = 256\n",
    "    num_heads = 8\n",
    "    batch_size = 1\n",
    "    \n",
    "    mha = MultiHeadAttention(d_model, num_heads)\n",
    "    \n",
    "    print(\"=== Autoregressive Generation with KV Cache ===\")\n",
    "    print()\n",
    "    \n",
    "    # Initial prompt\n",
    "    prompt_len = 5\n",
    "    x_prompt = torch.randn(batch_size, prompt_len, d_model)\n",
    "    \n",
    "    print(f\"Step 1: Process prompt (length {prompt_len})\")\n",
    "    out, _, cache = mha(x_prompt, use_cache=True)\n",
    "    print(f\"  Cache K shape: {cache[0].shape}\")\n",
    "    print(f\"  Cache V shape: {cache[1].shape}\")\n",
    "    print(f\"  Total cache size: {cache[0].numel() + cache[1].numel()} elements\")\n",
    "    \n",
    "    # Generate tokens one by one\n",
    "    num_new_tokens = 3\n",
    "    for i in range(num_new_tokens):\n",
    "        print(f\"\\nStep {i+2}: Generate token {i+1}\")\n",
    "        \n",
    "        # Process single new token\n",
    "        x_new = torch.randn(batch_size, 1, d_model)\n",
    "        out, _, cache = mha(x_new, kv_cache=cache, use_cache=True)\n",
    "        \n",
    "        print(f\"  Input: {x_new.shape}\")\n",
    "        print(f\"  Cache K shape: {cache[0].shape} (grew by 1)\")\n",
    "        print(f\"  Cache V shape: {cache[1].shape} (grew by 1)\")\n",
    "    \n",
    "    print(f\"\\nFinal sequence length: {prompt_len + num_new_tokens}\")\n",
    "    print(f\"Final cache size: {cache[0].shape}\")\n",
    "\n",
    "demonstrate_kv_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Memory Comparison\n",
    "\n",
    "Compare KV cache memory usage across different attention mechanisms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== KV Cache Memory Comparison ===\n",
      "Configuration:\n",
      "  Model: d_model=4096, num_heads=32, layers=32\n",
      "  Generation: batch=1, seq_len=2048\n",
      "  Precision: FP16 (2 bytes/param)\n",
      "\n",
      "MHA (Multi-Head Attention):\n",
      "  Total cache: 1.00 GB\n",
      "  Baseline (1.0x)\n",
      "\n",
      "MQA (Multi-Query Attention):\n",
      "  Total cache: 32.00 MB\n",
      "  Reduction: 32.0x smaller (96.9% less)\n",
      "\n",
      "GQA (Grouped Query Attention):\n",
      "  Total cache: 256.00 MB\n",
      "  Reduction: 4.0x smaller (75.0% less)\n",
      "\n",
      "MLA (Multi-Head Latent Attention):\n",
      "  Total cache: 128.00 MB\n",
      "  Reduction: 8.0x smaller (87.5% less)\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def compare_kv_cache_memory():\n",
    "    \"\"\"\n",
    "    Compare KV cache memory requirements across attention variants.\n",
    "    \"\"\"\n",
    "    # Model configuration\n",
    "    d_model = 4096\n",
    "    num_heads = 32\n",
    "    num_kv_heads = 8  # For GQA\n",
    "    latent_dim = 1024  # For MLA\n",
    "    \n",
    "    # Generation settings\n",
    "    batch_size = 1\n",
    "    seq_len = 2048\n",
    "    num_layers = 32\n",
    "    \n",
    "    head_dim = d_model // num_heads\n",
    "    bytes_per_param = 2  # FP16\n",
    "    \n",
    "    # Calculate cache size for each method\n",
    "    # Cache stores K and V for each layer\n",
    "    \n",
    "    # MHA: num_heads * head_dim = d_model per K or V\n",
    "    mha_cache_per_layer = 2 * batch_size * seq_len * d_model\n",
    "    mha_total = mha_cache_per_layer * num_layers * bytes_per_param\n",
    "    \n",
    "    # MQA: single head_dim per K or V\n",
    "    mqa_cache_per_layer = 2 * batch_size * seq_len * head_dim\n",
    "    mqa_total = mqa_cache_per_layer * num_layers * bytes_per_param\n",
    "    \n",
    "    # GQA: num_kv_heads * head_dim\n",
    "    gqa_cache_per_layer = 2 * batch_size * seq_len * num_kv_heads * head_dim\n",
    "    gqa_total = gqa_cache_per_layer * num_layers * bytes_per_param\n",
    "    \n",
    "    # MLA: latent_dim (compressed)\n",
    "    mla_cache_per_layer = batch_size * seq_len * latent_dim\n",
    "    mla_total = mla_cache_per_layer * num_layers * bytes_per_param\n",
    "    \n",
    "    # Print results\n",
    "    print(\"=== KV Cache Memory Comparison ===\")\n",
    "    print(f\"Configuration:\")\n",
    "    print(f\"  Model: d_model={d_model}, num_heads={num_heads}, layers={num_layers}\")\n",
    "    print(f\"  Generation: batch={batch_size}, seq_len={seq_len}\")\n",
    "    print(f\"  Precision: FP16 ({bytes_per_param} bytes/param)\")\n",
    "    print()\n",
    "    \n",
    "    def format_size(bytes_val):\n",
    "        mb = bytes_val / (1024 ** 2)\n",
    "        gb = bytes_val / (1024 ** 3)\n",
    "        if gb >= 1:\n",
    "            return f\"{gb:.2f} GB\"\n",
    "        return f\"{mb:.2f} MB\"\n",
    "    \n",
    "    print(f\"MHA (Multi-Head Attention):\")\n",
    "    print(f\"  Total cache: {format_size(mha_total)}\")\n",
    "    print(f\"  Baseline (1.0x)\")\n",
    "    print()\n",
    "    \n",
    "    print(f\"MQA (Multi-Query Attention):\")\n",
    "    print(f\"  Total cache: {format_size(mqa_total)}\")\n",
    "    print(f\"  Reduction: {mha_total / mqa_total:.1f}x smaller ({100 * (1 - mqa_total/mha_total):.1f}% less)\")\n",
    "    print()\n",
    "    \n",
    "    print(f\"GQA (Grouped Query Attention):\")\n",
    "    print(f\"  Total cache: {format_size(gqa_total)}\")\n",
    "    print(f\"  Reduction: {mha_total / gqa_total:.1f}x smaller ({100 * (1 - gqa_total/mha_total):.1f}% less)\")\n",
    "    print()\n",
    "    \n",
    "    print(f\"MLA (Multi-Head Latent Attention):\")\n",
    "    print(f\"  Total cache: {format_size(mla_total)}\")\n",
    "    print(f\"  Reduction: {mha_total / mla_total:.1f}x smaller ({100 * (1 - mla_total/mha_total):.1f}% less)\")\n",
    "    print()\n",
    "    \n",
    "    # Visualization\n",
    "    methods = ['MHA', 'MQA', 'GQA', 'MLA']\n",
    "    sizes_gb = [mha_total / (1024**3), mqa_total / (1024**3), \n",
    "                gqa_total / (1024**3), mla_total / (1024**3)]\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bars = plt.bar(methods, sizes_gb, color=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728'])\n",
    "    plt.ylabel('KV Cache Size (GB)', fontsize=12)\n",
    "    plt.title(f'KV Cache Memory Comparison\\n({num_layers} layers, seq_len={seq_len}, batch={batch_size})', \n",
    "              fontsize=14)\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar, size in zip(bars, sizes_gb):\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{size:.2f} GB',\n",
    "                ha='center', va='bottom', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "compare_kv_cache_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Performance Comparison\n",
    "\n",
    "Compare computational efficiency of different attention mechanisms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Attention Mechanism Benchmark ===\n",
      "Configuration: batch=4, seq_len=128, d_model=512\n",
      "Iterations: 100\n",
      "\n",
      "MHA     : 12.555 ms/iteration\n",
      "MQA     : 7.401 ms/iteration\n",
      "GQA     : 7.502 ms/iteration\n",
      "MLA     : 9.659 ms/iteration\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA90AAAJNCAYAAAAs3xZxAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjgsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvwVt1zgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAShtJREFUeJzt3QeYVdW9P+5FEawUEawoVsDeiV2vxt5b7Nh7xUquDTUxlqvGEktiS2JLjC1qjF30xo7GjqjYC6gIiIIGzu/5rv//zJ0uDLOZOTPv+zyH4ey9zz7rlD2zP3u1DqVSqZQAAACAZtex+XcJAAAACN0AAABQIDXdAAAAUBChGwAAAAoidAMAAEBBhG4AAAAoiNANAAAABRG6AQAAoCBCNwAAABRE6AZgunXo0CFtuOGG3rHpsO++++b36/33328V71eUI8oT5WoPRo0alXbYYYe04IILpo4dO6YePXq0dJFoJeJ3WBwLALOK0A3QTPbff/98IterV680ZcqUerd5/PHH8zZnnnlmqwxqlXYyGmWNW9euXdNXX31V7zbjxo1Lc8wxR9W2tF433HBD/ox+85vfzNR+pk6dmrbffvt0//33p6222iqdfvrp6ZRTTmm2crYHr732Who8eHDq169fPr66d++ellpqqbTjjjum3/72t6lUKrV0EQEqRueWLgBAWzBx4sT0l7/8JQeGr7/+Ot11113pF7/4RWpr3nzzzTTnnHOm1qRz587phx9+SDfddFM6+uij66yP5ZMnT87b/ec//0nt1cILL5w/vwhPbd3o0aPTG2+8kQ466KB0zTXXtHRxKs5DDz2Utt5663y8bLLJJrnFwOyzz57efffd9MQTT6Q777wzHXHEEfmYAuCn+W0J0Axuu+22NGnSpDRkyJB0ySWXpGuvvbZNhu4BAwak1mbJJZfMtW7XX399vaH7uuuuS/3798//HzlyZGqvZptttlb5+RXh008/zT8XWmihli5KRTrssMNya4GHH344bbTRRjXWxbH24IMPpk6dOrVY+QAqjeblAM0gQnbU+px00kn5JPWRRx5JH3zwQY1tokl5+QR22LBhVc2dy83JoxnnjTfemNcvvvjiVetq96GOWrwDDzwwLbroornZZ/RZjWbptZ8vlB//xRdf5Kai8803X25q/bOf/Sw3da+9bdRilf9fvlXvA9xQn+4vv/wyHXvssbncUaY+ffqkXXfdNTdRbagJfbyOSy+9NAfBeMxiiy2W35dp06bN4Luf0n777ZdefvnlNGLEiBrL//3vf6eXXnopr2/M3XffnTbeeOPUs2fPXKO3/PLLpwsvvDAHj4a233TTTXNXgtg+Pru999673tcbIWV6Xuf48ePTeeedlzbYYIMcFrt06ZJ/7rPPPrmGsbb4PsX7GJ/jzTffnFZeeeX82cb34Zhjjknff//9dPXp/uyzz/L2Sy+9dH589H0eOHBgOvTQQ3OZan9u7733Xn5vlllmmbz9sssum2699da8TbQ4+O///u/8fsT7suKKK6Z//OMfaWbF/uL27bff5rLG+xLvZez/9ttvr7NtvIe1j7PqXTqinBdddFFaddVV01xzzZXmmWeetN5666V77rmnznNXf93/8z//k19vPHf193HMmDHpuOOOy82vY10cZzvttFO934cZeS3Vy3vxxRenNdZYI5d17rnnzuWIi3zRfaK6GSlLfeLx8X2LY6B24A7xXmy22WY1umpU7zbz1FNP5d8RUc74LsVzv/POOw0+14yUdUa3j7LEdyE+4zhW40LoRx99NF3vA0CzKgEwU15//fXo3Fjacsst8/0bb7wx3z/jjDNqbPfYY4+VBg8enNdtsMEGeX35Nm7cuNLFF19cWmmllfL6Y445pmrd9ddfX7WPZ555ptS9e/dS586dS9tvv33pxBNPLO2yyy75fp8+fUrvvvtujeeMfcU+l1pqqdJqq61WOvbYY0t77LFHqVOnTqUuXbqUXn311apt47kWW2yxqrKXb3feeWeN/UXZqxszZkxpySWXzOs23HDD0imnnFL6xS9+kZ9jzjnnLD355JM1ti+/BzvttFNpvvnmK+27776lo48+urTooovm5b/85S+n+72P7fv371/69NNP8/MdeeSRNdYfddRReXmsj+3q+7MX5Y3lCy+8cGn//fcvHXfccaXVV189L9t5553rbD9kyJC8bt55583bx+P33HPP0gILLJA/w6a+zqeffjp/Jptttlnp8MMPz5/tNttsk8sfz/X+++/X2D4+m/L+55prrvy5RtkHDhyYl8f96kaPHp2XR7nKJk2aVFp88cVLHTp0yM8bzxnfvW233TZ/dqNGjarzerbbbrv8Wg866KDSoYceWurRo0d+/AMPPFDaaqut8v6i/PHezD777KXZZput9M4770zX5xnf9XiOc889t8by+F4utNBCpbXWWqs0YMCA/DnH/qOM8dz//Oc/q7aNz6C+4yyOvzB58uT8PY31K6+8cv6OxOvo27dvXnbZZZfVeO7yvuL4js9h7733Lp100kmlCy+8MK+P17bIIovkbTbddNPS8ccfn7eJssXnEsdsU19L+O6770rrrLNO3v/SSy+dy3vCCSfkzyEe89JLL1VtO6NlqU+8P+XfJ99+++10fW7x3sZzxncovsPx/Rk6dGj+Ga+pd+/edX43zWhZZ3T7hx9+OH/3unbtWtpnn33ycbrGGmvkz3nFFVes93cBQFH8xgGYSeUQdsstt+T7EydOzCeBEa6mTp1a78lp7UBe+wQ/AlJtP/zwQ6lfv36leeaZpzRixIga6yLYRjjbeuutayyPfcUtQlD1svzhD3/Iyw855JAa20dIaexktL7Qvd9+++XlcZJd3X333ZeXR+Cv/tzl1xjhLMJw2dixY3OAi9c3ZcqUBstQuzwRpkO89ghFERpC/Iz7EVxDfaH7wQcfrAoL1QPGtGnTchCLdbfffnvV8r///e952QorrFD68ssva+zrxx9/LH3++edNfp3ffPNN6auvvqrzGh999NFSx44dSwceeGC9oTsuwrz11ls1QtoyyyyTH/PJJ580GrrvueeevCwuxtQW3+Pye1n99cS+40JL2bPPPpuXx2tad911a7yPt912W14XQXFmQ3c58Fd/zyJYlT+/6T3O4mJHrDvttNPy51w2YcKEfLElQmP19638uiPwffDBB3X2t/baa+djLy46VDdy5Mj8Gcd3ZWZeS4TLWB4B8z//+U+NdfGdic+pqWVpyI477lj1Pb/00ktLL7zwQqPHZPn9jttVV11VY13cj+W1fzfNaFlnZPv4fbPEEkvkwF/9ol983nExqlxWgFnFbxyAmRBBOGpxunXrVvr++++rlu+11175pK52rdXMhO477rgjrzvrrLMaPFGOoDV+/PiqZbF9XACofmJeDohRm7XqqqvOVOiOE/GozezVq1euNa3t5z//eX7M8OHD67zG6667rsHX/8orrzRYhoZCd/n9ufXWW/P9+Bn3yzX19YXuqImLZfWFqQg0cdIeNcllW2yxRd4+gvBPac7XGYEiLrjUF7pPP/30OtuX10Wonp7QXfuCSWOvJ1py1BYBJ9Y98cQTNZZHSIzaxvXXX79ZQvd7771X5zGxLi6uTM9xFmGsZ8+euWVG9cBd+/2oXttdft2//e1v62wfF79iXdRUN3ZBrnqLkhl5LXGcRqCMCytff/11vc8xM2VpSFxQiotV5XAat7gYEcE33oe4sFPf+x0XZGpfaIz7UUMfx1L5Ys2MlnVGt4/vYdwvX3CrLlqMRHgXuoFZyUBqADMh+vaOHTs2HXDAAbkPa1n0w/3zn/+c+3pH39/m8Mwzz1QNBlbflGOff/557if89ttvp9VXX71qefS9jT6g1UX/8/nnnz998803M1Wmt956K48MHn0/6xvVPJbHSMjR3zr6zFa32mqr1dl+kUUWyT+bUq4YbTn6ksfAadF3M37G/Vje2Hsa/T1j2/pEn+V4jWXPPfdc7kta7jM8PWbkdUbf2BiI79lnn8395KuPth59vGd2/7Wtv/76uQ94TNEV/d/jvYrXFn26G5peLfqO1xb7iD7PtdfFYFvxGZQHNpsZ0T84xgyo77U+/fTT07WPOHaiD3T0o47+3rXFsRyqf+Zla665ZoPHZIyZUN8xWd5P/Iw+0jP6WuJxMTNCjCAe4w00pqllqU/0f47+7THX+QMPPJC/97H/f/3rX/n2+9//Po//MO+889Z43DrrrJPnRK8u7sfy2Fd8x+K1zGhZZ3T7eJ5Q+3dOiDEV+vbt22LTMgLtk9ANMBMiVJdDdnUxKFdM0RShPKYQq31y2hSxn/IUWI2JUdSr69atW73bRfBuaKCw6TVhwoT8MwJ8fSKMVd/up8pVnoKoKeWK0bn32muvHFojGMTIyzHoUmPTGsV7GsG2vgBW3/sZA4vF51o7WDRmel/nX//613yxIC6QxEBVMdhWXMiI8BvzV9c3UN6M7L8+MX1YBJqYx/rvf/97ntc6RCiJea0PP/zwGXq+htb9+OOPaWY1NNVZ7H96B98rH0Ovv/56vk3vMdTQd7y8v/vuuy/fpnd/0/taygPZxXfupzS1LI2JwfXiVhYXz+IYi4HL4piJ+bqra+j3QHl5+fXMaFlndPvy88QFn4bKI3QDs5LQDdBEMQpuTJ0TGqv5jBrv+qaymlHlQBPhqLHa21mpXKaogapP1L5X365o0eIgRqWOkdMjvMT9xkS5ItRGrfL0iBrKcouCGQne0yNq8KK1xIsvvlgj6ITy6OBFiFHwI9THa3rllVfydzpGW495mKN2dffdd09tRfl7GCNeNzRSeEPqq/kv7++yyy5LRx55ZGpu8X0Ln3zyyU9uW3RZQrRkiP3/13/9V3r00UfrrG/o90B5efliw4yWdUa3Lz9PjHbeWHkAZhVThgE0UTmorLvuujnc1b7FFF3Va8NDeW7bhmogG1s/aNCg/HN6m9I2xU+Vr7aYBiuC4vPPP5++++67OuvL05LV1yS5CDGNUrxPEVJiWrRoJt2Y2Parr77KTV+nRzQxnjJlStXUas0ppmmK8tYO3DGlVzTdLlpcRIjPKaa9u+WWW/Ky+qbQqmTx/kaAe+GFF5ql9r3oYzLml4/yxvFVe2qwWV2WstpdVar73//93zqtDuJ+tDyJixYrrbRSk8o6o9uXn+fJJ5+ssy5ajJg2DJjVhG6AJogxvK6//vp8Ihlza//hD3+oc4tQvtZaa+XawzjJD+Vm5g2d9DW2frvttsu1klGTO3z48DrrI0TEvLQz46fKV1v0M46a0KgpPvfcc2usi76g//znP/OcutGnc1aJ/tl33nlnjYsdDSm3QNh///1z+K4tarXffPPNqvtR+xtifuVyk9eyaKY+MzVo0dc05jOuvo/oL3/YYYc1S0CsTzSxrq/M5WXVxyloC6L5dryfEbxOOOGEet/XaDrdUA1pfRdhIhDGRYrbbrutzvoInDNzgSbKe8ghh+Tm0vGdq30xLJbHfN/NWZZoov2rX/2q3tYf8R2/4IIL8v/jYmNtMZ5E9PeuLu7H8q222ir17t27SWWd0e2jbNFn/t57763xOzF+b//yl7+c6W41ADNK83KAJoimlaNHj87NypdYYokGt9tvv/1y7UwEwBjcLGqGYxCnaC4cA3LFwEkR3I866qjcJDKabV544YXp4IMPzk1gY5CvCGN777133j6axG6xxRb5eWPbFVZYIT8+QkTU6sQASPUNAjW9Yp/xHPHc8TwRuqLWaJtttmnwMeedd14+4T3nnHNyjVacHEd/yeijHH2S4+JEczfF/qna7rhNj8033zyddtpp6eyzz84XB+J+vN8RwCMAx3sar6tcY77lllvmsBafUdRI77DDDrnfaNSsP/LII3ndscce26Ryx3cgbqusskraeeedc8CJQegiKMRnUB4cqjnF/k888cR8USQG3IvvT9SqRw13fPbliwxtSfRFHjFiRG5CH/2DYzC58mf46quv5vc5jtmG+gPXFkEwBgzcbbfd8ngCq666ah6A78MPP8z7icHZ4uJJU5111lm53/2f/vSn/DOOy/hdEJ9TXNiKUFluSdIcZYkLEaeeemru7hAXDeO7F7XtcSEmLqJ9/PHHOdCeccYZdR4bYxHEhawYG2C55ZbLF3WiO8x8881Xp//3jJZ1RraP3zfXXHNNPl5j4LYYKyF+78bv7Wg5suKKK+aLoQCzzCwdKx2gjdh9993zlDMxxVFjYvquOeaYI0/5U55m55lnnsnTbsVUQOXpeKpPEXb++efnKXZiqqX65sX++OOPS8ccc0zepmvXrnm6soEDB+Z5nB955JEa29b3+OrTE8Wtupii6KSTTspzjMeUYrWnmGpofzH39NFHH533F+Web775SjvvvHO90xM1Ni1aeaqrmIJoRqcM+yn1TRlW9tBDD+XphWL6tyj/AgssUFprrbVKZ599dunDDz+ss/3f/va30kYbbZQ/1/gMYjqvmEf5tddea/LrjCmsYk7j5ZZbLk/DFmU44IAD8jRL9U3l1th7VZ56q/r3s74pw9544438XVpllVXytG/xWmL6r9jm9ddfr7HPxl5PY1PN1fc9a8qUYQ3to77n/qmp+WIqs6uvvrq0zjrr5OMnXnd85zfffPPSlVdeWWOu8cZed1lM53XqqaeWll9++Xy8zz333Pn4jDmhYyq7mXktIeZLv/DCC0srr7xy1f6XXXbZPIf3uHHjmlyW+sQUX/fff3/+Xqy22mql+eefP/8uiPcp5jEfNmxYnk6vofc75sWO1xFTFcZjdthhh9KoUaNm+n1ryvYxVWFMVxfbxlRsu+yyS54e8KemRgRobh3in1kX8QEAaEti7IaohY7a7/qm9AJo7/TpBgAAgIII3QAAAFAQoRsAAAAKok83AAAAFERNNwAAABSk3c3TPW3atPTpp5+meeaZJ89tCwAAADMqJgKbOHFiWmihhVLHjg3XZ7e70B2Bu2/fvi1dDAAAANqAjz76KC2yyCINrm93oTtquMtvTLdu3Vq6OAAAAFSgCRMm5ArdcsZsSLsL3eUm5RG4hW4AAABmxk91WzaQGgAAABRE6AYAAICCCN0AAABQEKEbAAAACiJ0AwAAQEGEbgAAACiI0A0AAAAFEboBAACgIEI3AAAAFEToBgAAgIII3bSY4cOHp2222SYttNBCqUOHDumuu+6qsf7HH39MJ598clphhRXSXHPNlbfbZ5990qefftrofs8888y8v+q3AQMG1Nhmww03rLPNoYceWsjrBAAA2i+hmxYzadKktNJKK6Urrrii3vXfffddGjFiRDrttNPyzzvuuCONHDkybbvttj+57+WWWy599tlnVbennnqqzjYHHXRQjW3OP//8ZnldAAAAZZ2r/gez2BZbbJFvDenevXt66KGHaiy7/PLL05prrpk+/PDDtOiiizb42M6dO6cFFlig0eefc845f3Kb6vr165cOPPDA9Pbbb+cLAL169UqXXXZZWmuttfLyRx55JC2xxBLpuuuuS6uvvnp+zAcffJCOPPLIHPp/+OGHvI8LLrggbbnlltP9vAAAQOVS001FGT9+fG4K3qNHj0a3GzVqVG6OHiF4zz33zCG9tptuuinNN998afnll09Dhw7NNes/5eKLL07rrLNOeumll9JWW22V9t5779zkfa+99sq18UsuuWS+XyqV8vZHHHFEmjJlSm5K/+qrr6bzzjsvzT333DPxDgAAAJVETTcVY/LkybmP9+677566devW4HaDBg1KN9xwQ+rfv39uNj5s2LC03nrrpddeey3NM888eZs99tgjLbbYYjmYv/LKK3m/0XQ9arAbEzXUhxxySP7/6aefnq688sq0xhprpF122SUvi/1EzfcXX3yRa9Ej7O+00065X3qIiwAAAED7IXRTEWJQtV133TXXIEfQbUz1JusrrrhiDuERsP/yl7+kAw44IC8/+OCDq7aJQLzgggumjTfeOL377ru5trohsb+y+eefv+rxtZeNGTMmh+6jjz46HXbYYenBBx9Mm2yySQ7g1fcBAAC0bZqXUzGBO/pHRx/vxmq56xNN0ZdZZpn0zjvvNLhNBPPQ2DZhttlmq/p/NHNvaNm0adPyz+jr/d577+Vm6NG8PPp6Rz9wAACgfRC6qYjAHX20H3744Tx42Yz69ttvcw121GY35OWXX84/G9umqfr27ZunI4um68cff3z6/e9/3+zPAQAAtE6al9NiIgxXr1kePXp0Dr/zzjtvHpk8AvfOO++cByi7995709SpU9Pnn3+et41tunTpkv8fzcJ32GGHPEp4OOGEE/L839GkPOb0PuOMM1KnTp1yX/AQAfzmm2/O/bMjxEef7uOOOy6tv/76zd70+9hjj83N3aOmfdy4cemxxx5LAwcObNbnAAAAWi+hmxbzwgsvpI022qjq/pAhQ/LPwYMH54HQPvnkk3TPPffkZSuvvHKNx0Z43XDDDatC9Jdfflm17uOPP84B+6uvvkq9e/dO6667bnrmmWfy/0OE9ag1v+SSS/Jc4VETHX2tTz311GZ/jXGhIEYwjzJFs/jNN988j4AOAAC0Dx1K5bmN2okJEybk+Z9j6qkZ7RsMAAAAM5It9ekGAACAgmhe3or1O+W+li4CNNn7v9nKuwcAQLunphsAAAAKInQDAABAQYRuAAAAKIjQDQAAAAURugEAAKAgQjcAAAAUROgGAACAggjdAAAAUBChGwAAAAoidAMAAEBBhG4AAAAoiNANAAAABRG6AQAAoCBCNwAAABRE6AYAAICCCN0AAABQEKEbAAAACiJ0AwAAQHsI3cOHD0/bbLNNWmihhVKHDh3SXXfdVbXuxx9/TCeffHJaYYUV0lxzzZW32WeffdKnn37aomUGAACAigjdkyZNSiuttFK64oor6qz77rvv0ogRI9Jpp52Wf95xxx1p5MiRadttt22RsgIAAMBP6ZxakS222CLf6tO9e/f00EMP1Vh2+eWXpzXXXDN9+OGHadFFF633cVOmTMm3sgkTJuSf06ZNy7fWrGMqtXQRoMla+/EFAACz4ny3VYXuGTV+/PjcDL1Hjx4NbnPuueemYcOG1Vk+duzYNHny5NSaDewpdFO5xowZ09JFAACAwkycOLFth+4IzNHHe/fdd0/dunVrcLuhQ4emIUOG1Kjp7tu3b+rdu3ejj2sN3hzXoaWLAE3Wp08f7x4AAG3W7LPP3nZDdwyqtuuuu6ZSqZSuvPLKRrft2rVrvtXWsWPHfGvNpiWhm8rV2o8vAACYFee7nSs1cH/wwQfp0UcfbfW11QAAALRfnSsxcI8aNSo99thjqVevXi1dJAAAAKiM0P3tt9+md955p+r+6NGj08svv5zmnXfetOCCC6add945Txd27733pqlTp6bPP/88bxfru3Tp0oIlBwAAgFYeul944YW00UYbVd0vD4A2ePDgdOaZZ6Z77rkn31955ZVrPC5qvTfccMNZXFoAAACooNAdwTkGR2tIY+sAAACgtTG8MAAAABRE6AYAAICCCN0AAABQEKEbAAAACiJ0AwAAQEGEbgAAACiI0A0AAAAFEboBAACgIEI3AAAAFEToBgAAgIII3QAAAFAQoRsAAAAKInQDAABAQYRuAAAAKIjQDQAAAAURugEAAKAgQjcAAAAUROgGAACAggjdAAAAUBChGwAAAAoidAMAAEBBhG4AAAAoiNANAAAABRG6AQAAoCBCNwAAABRE6AYAAICCCN0AAABQEKEbAAAACiJ0AwAAQEGEbgAAACiI0A0AAAAFEboBAACgIEI3AAAAFEToBgAAgIII3QAAAFAQoRsAAAAKInQDAABAQYRuAAAAKIjQDQAAAAURugEAAKAgQjcAAAAUROgGAACAggjdAAAAUBChGwAAAAoidAMAAEBBhG4AAAAoiNANAAAABRG6AQAAoCBCNwAAABRE6AYAAICCCN0AAABQEKEbAAAACiJ0AwAAQEGEbgAAACiI0A0AAAAFEboBAACgIEI3AAAAFEToBgAAgIII3QAAAFAQoRsAAAAKInQDAABAQYRuAAAAKIjQDQAAAAURugEAAKAgQjcAAAAUROgGAACAggjdAAAAUBChGwAAANpD6B4+fHjaZptt0kILLZQ6dOiQ7rrrrhrrS6VSOv3009OCCy6Y5phjjrTJJpukUaNGtVh5AQAAoGJC96RJk9JKK62UrrjiinrXn3/++enSSy9NV111VXr22WfTXHPNlTbbbLM0efLkWV5WAAAA+CmdUyuyxRZb5Ft9opb7kksuSaeeemrabrvt8rI//vGPaf7558814rvtttssLi0AAABUUOhuzOjRo9Pnn3+em5SXde/ePQ0aNCg9/fTTDYbuKVOm5FvZhAkT8s9p06blW2vWMZVaugjQZK39+AIAgFlxvlsxoTsCd4ia7erifnldfc4999w0bNiwOsvHjh3b6pulD+wpdFO5xowZ09JFAACAwkycOLFthe6mGjp0aBoyZEiNmu6+ffum3r17p27duqXW7M1xHVq6CNBkffr08e4BALM8BMXAy9H9NCoAVllllXTxxRenNdZYo9HHRcvYs88+O9100025Qi8Gbo5urfvvv3/VNt98801eduedd6avv/46LbbYYumiiy5KW2655Sx4ZbRGs88+e9sK3QsssED++cUXX+SDoCzur7zyyg0+rmvXrvlWW8eOHfOtNZuWhG4qV2s/vgCAtufggw9Or732WvrTn/6UZ0T685//nDbddNP0xhtvpIUXXrjBx0VX1cgV1157bVpqqaXSZ599lpsOl89nfvjhhzyAc1Qq3H777XlfH3zwQerRo4dznnas43Se71bMWfHiiy+eg/cjjzxSo9Y6RjFfa621WrRsAABAy/r+++/T3/72tzzj0frrr5/D85lnnpl/XnnllQ0+7oEHHkhPPPFEuv/++/P4Uf369cv5Yp111qna5rrrrsu121GDHstjmw022CDPvNSQG264IYfye++9N/Xv3z/NOeecaeedd07fffdduvHGG/M+evbsmY4++ug0derUqsf97ne/S0svvXSuRY2utPEYKlurqun+9ttv0zvvvFNj8LSXX345zTvvvGnRRRdNxx57bDrnnHPylzBC+GmnnZavYG2//fYtWm4AAKBl/ec//8nhtXaT3znmmCM99dRTDT7unnvuSauvvnoO61FDHtMSb7vttrm5eTy2vE0E8SOOOCLdfffduavqHnvskU4++eTUqVOnBvcdATumPL711ltz0/cdd9wx7bDDDjmMR8h/77330k477ZSD/C9+8Yv0wgsv5BAe5Vh77bVz0H/yySeb8V0itffQHV+yjTbaqOp+uS/24MGD85Wik046Kc/lHc1Gok/Fuuuum69MTW9begAAoG2aZ555cjCOsDxw4MBcS3zLLbfkmY6itrshEXwjlEemiP7aX375ZTr88MPTV199la6//vqqbR599NG055575rAcFYWxzY8//pjOOOOMBvcd66OWfckll8z3o9Y6AnU0ZZ977rnTsssum/PPY489lkP3hx9+mEP/1ltvnV9P9BuPfulUtlYVujfccMM8H3dDOnTokM4666x8AwAAqC4CbQx+Fn2uowZ61VVXTbvvvnt68cUXG3yjou925IwYRC2mJA4xQFoE5GjqHbXdsU30577mmmvyfldbbbX0ySefpAsuuKDR0B1NysuBO8SFgGhWHoG7+rLyrC8///nPc9BeYokl0uabb55vUTMe+6FyVUyfbgAAgMZEwI3+2dFt9aOPPkrPPfdcrm2OENuQGKQ5Qno5cIeoKY/KwI8//rhqm2WWWaZGU/LYJkY6j0HWGjLbbLPVuB/hvr5l5fmeo3Z7xIgRuYY+njNGYo9+49HKl8oldAMAAG1KNNGO0Dpu3Lj0z3/+M2233XYNbhv9qT/99NMc1MvefvvtPDL1IossUrVNNCkvh+PyNvEcXbp0adayd+7cOQ/oFn3MX3nllfT+++/npu1ULqEbAABoEyJgx5hPMSDzQw89lPtLDxgwIO23335V2wwdOjTts88+VfdjQLRevXrlbWJqseHDh6cTTzwxN1MvD6R22GGH5UHNjjnmmBy277vvvvTrX/86D6zWnGKk8xh4LQaTjinJ/vjHP+agH6OfU7laVZ9uAACApho/fnwO1dEsPGZAipHBf/WrX9Vo0h1zcMeAZWXRvzoC+lFHHZVHMY8Avuuuu+ZZk8r69u2bA/1xxx2XVlxxxdwcPQJ4jF7enGJU8zvuuCNPdTZ58uQ8a1M0NV9uueWa9XmYtTqUGhu5rA2Kub2jv0YckN26dUutWb9T7mvpIkCTvf+brbx7AACk9p4tNS8HAACAgmheDgAAbdCbAwa2dBGgyQa+9WZqK9R0AwAAQEGEbgAAACiI0A0AAAAFEboBAACgIEI3AAAAFEToBgAAgIII3QAAAFAQoRsAAAAKInQDAABAQYRuAAAAKIjQDQAAAAURugEAAKAgQjcAAAAUROgGAACAggjdAAAAUBChGwAAAAoidAMAAEBBhG4AAAAoiNANAAAABRG6AQAAoCBCNwAAABRE6AYAAICCCN0AAABQEKEbAAAACiJ0AwAAQEGEbgAAACiI0A0AAAAFEboBAACgIEI3AAAAFEToBgAAgIII3QAAAFAQoRsAAAAKInQDAABAQYRuAAAAELoBAACgsqjpBgAAgIII3QAAAFAQoRsAAAAKInQDAABAQYRuAAAAKIjQDQAAAAURugEAAKAgQjcAAAAUROgGAACAggjdAAAAUBChGwAAAAoidAMAAEBBhG4AAAAoiNANAAAABRG6AQAAoCBCNwAAABRE6AYAAICCCN0AAABQEKEbAAAACiJ0AwAAQEGEbgAAACiI0A0AAAAFEboBAACgIEI3AAAAFEToBgAAgIII3QAAAFCQigrdU6dOTaeddlpafPHF0xxzzJGWXHLJdPbZZ6dSqdTSRQMAAIA6OqcKct5556Urr7wy3XjjjWm55ZZLL7zwQtpvv/1S9+7d09FHH93SxQMAAIDKDd3/+te/0nbbbZe22mqrfL9fv37plltuSc8991xLFw0AAAAqO3Svvfba6Zprrklvv/12WmaZZdK///3v9NRTT6WLLrqowcdMmTIl38omTJiQf06bNi3fWrOOSbN5KldrP74AoK0rdayonqRQceeS01vGigrdp5xySg7NAwYMSJ06dcp9vH/1q1+lPffcs8HHnHvuuWnYsGF1lo8dOzZNnjw5tWYDewrdVK4xY8a0dBEAoF2b1L9/SxcB2vS55MSJE9te6P7LX/6SbrrppnTzzTfnPt0vv/xyOvbYY9NCCy2UBg8eXO9jhg4dmoYMGVJ1P0J73759U+/evVO3bt1Sa/bmuA4tXQRosj59+nj3AKAFfT1ypPefitWnAs4lZ5999rYXuk888cRc273bbrvl+yussEL64IMPcm12Q6G7a9eu+VZbx44d8601m5aEbipXaz++AKCt61ABzXOhks8lp7eMrf+VVPPdd9/VeWHRzLwS2vsDAADQ/lRUTfc222yT+3AvuuiiuXn5Sy+9lAdR23///Vu6aAAAAFDZofuyyy5Lp512Wjr88MNzx/roy33IIYek008/vaWLBgAAAJUduueZZ550ySWX5BsAAAC0dhXVpxsAAAAqidANAFCwfv36pQ4dOtS5HXHEEQ0+5oYbbqizfe3paUqlUu5mt+CCC6Y55pgjbbLJJmnUqFE+T4BWROgGACjY888/nz777LOq20MPPZSX77LLLo0+rlu3bjUeF1OlVnf++eenSy+9NF111VXp2WefTXPNNVfabLPN0uTJkwt9PQBMP6EbAKBgvXv3TgsssEDV7d57701LLrlk2mCDDRp9XNRuV3/c/PPPX6OWO8a5OfXUU9N2222XVlxxxfTHP/4xffrpp+muu+5qcJ8bbrhhOuqoo9Kxxx6bevbsmff5+9//Pk2aNCntt99+eQydpZZaKv3jH/+oesy4cePSnnvumV9H1KgvvfTS6frrr2+mdwegbRO6AQBmoR9++CH9+c9/zlOeRqhuzLfffpsWW2yx1Ldv3xysX3/99ap1o0ePTp9//nluUl7WvXv3NGjQoPT00083ut8bb7wxzTfffOm5557LAfywww7Lte5rr712GjFiRNp0003T3nvvnb777ru8fcwe88Ybb+Qg/uabb6Yrr7wyPx6AnyZ0A7RTTeljWt2tt96at99+++1rLNfHFBoXtdDffPNN2nfffRvdrn///um6665Ld999dw7p06ZNy6H4448/zusjcIfqtd/l++V1DVlppZVyDXnUWA8dOjT3FY8QfdBBB+Vl0U/8q6++Sq+88kre/sMPP0yrrLJKWn311fPvjgj622yzjY8aYDoI3QDtVFP7mIb3338/nXDCCWm99dars04fU2jctddem7bYYou00EILNbrdWmutlfbZZ5+08sor52bod9xxR27effXVV8/0WxxN0cs6deqUevXqlVZYYYWqZeUgP2bMmPwzasLjQluU5aSTTkr/+te/ZroMAO2F0A3QTjW1j+nUqVNz385hw4alJZZYosY6fUyhcTEQ2sMPP5wOPPDAGX6rZptttlzb/M477+T7cdyGL774osZ2cb+8rrF9VRetVqovKzd7j9r1EBcJouzHHXdc7jO+8cYb5wtvAPw0oRuAGepjetZZZ6U+ffqkAw44oM46fUyhcTH4WBw/W2211Qy/VXHB69VXX83Tg4XFF188h+tHHnmkapsJEybkUcyjlryIC3WDBw/OvytiALdrrrmm2Z8DoC3q3NIFAKBy+pg+9dRTuWnsyy+/XO/65uhjGqKP6W9+85uqPqYh+pjG4E3Rx/RnP/tZjT6mIfqZQmsWtcYRuiO4du5c9xQsmpIvvPDC6dxzz626wBXf9RhJPI7PCy64INc2l2vJ4wJZjEB+zjnn5H7YEcJjwLNotl57rIWZFcffaqutlpZbbrk0ZcqU3DJm4MCBzfocAG1Vk0J3/OKPvjwxiuWXX36Zf+nHiVH88o0rqzH9BABtq4/pxIkT82jGMbVQEaMWN6WP6U477VQ10nKEjBhkClqraFYeF4uiRUl9Yl3Hjh1rTNMVF53iglWcW0XojfOvZZddtmqb6F8dU30dfPDB+fxs3XXXTQ888EAeGK05denSJV8Mi/EcYsqwGM8h+ngD0IyhO5oe3nzzzemGG27INR3lPj61xR+LddZZJ8/zuPvuu6euXbtO71MA0IJ9TGOQpsa8++67+YS7+ojF5b8FUWs3cuTIGn1My01gy/djAKYi+pjef//9eRC46GMaI69feOGFM/DqYdaJi0Mx7kFDHn/88Rr3L7744nxrTBwXUSMet+lV+3lCHNu1VS9rtEIpt0QBoIA+3VdddVUeLOfQQw9N3bp1y38AInjHQBrff/99nsPxk08+ycsuuuiiPEdkbBsD8jTHCJsAtHwf0wEDBuT+pNG0vHzbdttt00YbbZT/H/MI62MKANCEmu5f//rXeYTKqL2OQF2fqNGIWzTtO/roo/NAHjG3ZPRLOuSQQ6bnaQBoxX1Mo7nq8ssvX2N9jx498s/qy/UxpTEr3Ph/XQag0rw6+NWWLgLQVkP3e++9V+/JWGOiRjxOvI488simlg2AVtbHdHroYwoA8H86lBrrXNQGRQ181NaPHz8+Xxhozfqdcl9LFwGa7P3fzPh0OEDbp6abSlZpNd1vDjDCPJVr4FtvpraSLZs0enmMYBsjZEb/vbLo3x19v2MaiRhNds0112xayQEAAKCNaFLojmkpRo8enZ555pmqhB/zSH788ce5GeJvf/vbPF3Fhhtu2NzlBSjGmfWPVwGt3pnjW7oEAEAjZqyj3v8vRinfeuutq+7/+c9/zjXdMXdkzCkZc62ec845Tdk1AAAAtO/Q/eWXX+bRbMvuueeetO666+ba7nnmmSePdvvvf/+7OcsJAAAA7SN0xxQxn3/+ef5/zNP95JNPpk033bRqfYx0HnN3AwAAQHvWpD7dMRf37373uzRgwIDcd3vy5Mlpu+22q1r/9ttv16gJBwAAgPaoSaH7vPPOyzXbMUp5OP7449Nyyy2X/z916tT017/+NW2++ebNW1IAAABoD6F7qaWWSiNHjkxvvPFGnpesX79+VeuiWfnll1+eVlpppeYsJwAAALSP0B1mm222eoN1DKRWvak5AAAAtFdNDt3hww8/TO+9916eJqxUKtVZv+OOO87M7gEAAKD9he4I2/vvv3967LHH8v36AneHDh1y/24AAABor5oUugcPHpyefvrpdMopp6RBgwblft0AAABAM4TuZ555Jp188slp2LBhTXk4AAAAtAsdm/KgRRZZJPXs2bP5SwMAAADtPXSfcMIJ6dprr83TgwEAAADN2Lz8kEMOyYOkLb300mnnnXfONd+dOnWqM5Dacccd15TdAwAAQPsN3a+99lo6//zz02effZYuu+yyercRugEAAGjvmhS6Dz744DR+/Ph09dVXG70cAAAAmjN0v/zyy3nk8oMOOqgpDwcAAIB2oUkDqS2++OLNXxIAAABoY5oUuqOW+4orrkgfffRR85cIAAAA2nPz8uHDh6cePXqk/v37p0022ST17du33tHLf/vb3zZXOQEAAKB9hO7LL7+86v/33ntvvdsI3QAAALR3TQrd06ZNa/6SAAAAQBvTpD7dAAAAQDOF7u+++256Nmv2xwIAAECbD90xUNpZZ52VPvvss+ne8SeffJJOP/30tOiii85M+QAAAKBt9+m+8sor05lnnpmD9zrrrJNHLF911VXzfN09e/ZMpVIpjRs3Lo0ePTq98MIL6eGHH07PPPNMWnrppdPvfve74l8FAAAAVGro3nXXXdPOO++c7rnnnnTDDTekX/3qV+mHH37II5RXF+G7S5cuadNNN02333572nbbbVPHjrqNAwAA0D5N9+jlEZ633377fJsyZUp68cUX01tvvZW++uqrvL5Xr15pwIABabXVVktdu3YtsswAAADQdqcMi1C99tpr5xsAAABQP22/AQAAoCBCNwAAABRE6AYAAICCCN0AAABQEKEbAAAACiJ0AwAAQGsL3R9++GE69NBDU//+/dO8886bhg8fnpd/+eWX6eijj04vvfRSc5YTAAAA2sc83W+88UZab7310rRp09KgQYPSO++8k/7zn//kdfPNN1966qmn0qRJk9K1117b3OUFAACAth26TzrppNSjR4/0zDPPpA4dOqQ+ffrUWL/VVlul2267rbnKCAAAAO2neXk0JT/ssMNS7969c+iubdFFF02ffPJJc5QPAAAA2lfojmblc845Z4Prx44dm7p27Toz5QIAAID2GbpXXXXVdN9999W7Lvp233rrrelnP/vZzJYNAAAA2l/oHjp0aHrggQdyE/PXXnstL/viiy/Sww8/nDbddNP05ptvplNOOaW5ywoAAABtfyC1LbbYIt1www3pmGOOSddcc01ettdee6VSqZS6deuW/vjHP6b111+/ucsKAAAAbT90h7333jvtuOOO6cEHH8xThkU/7yWXXDJtttlmaZ555mneUgIAAEB7Ct1hrrnmSjvssEPzlQYAAADakJkK3T/++GOeGmzcuHG5aXl9A64BAABAe9Wk0P3NN9+kE044Id10003phx9+qLM+AnjM3z116tTmKCMAAAC0n9C97777pr///e9pt912S4MGDUrdu3dv/pIBAABAewzdMXja0UcfnS6++OLmLxEAAAC053m6e/XqlZZaaqnmLw0AAAC099B98MEHp1tvvTVPEwYAAAA0Y/Py0047LU2ZMiWtvvrqeb7uRRZZJHXq1KnOdjGPd3OL0dJPPvnk9I9//CN99913ucb9+uuvz2UBAACAig/dEXwfffTR9PLLL+dbfYoYvTymJltnnXXSRhttlEN3796906hRo1LPnj2b9XkAAACgxUL3/vvvn0aMGJGGDh06S0cvP++881Lfvn1zzXbZ4osv3uhjokY+bmUTJkzIP6NpfGtvHt8x1Z37HCpFaz++mqm3DbS8CjvWOjrWqGCV9ret1NHfNirXtAo43qa3jE0K3U899VRu4j1s2LA0K91zzz1ps802S7vsskt64okn0sILL5wOP/zwdNBBBzX4mHPPPbfeco4dOzZNnjw5tWYDewrdVK4xY8akitJtxZYuATRNhR1rS3deuqWLAO3mb9uk/v1bugjQpo+3iRMnFhe6F1hggTTvvPOmWe29995LV155ZRoyZEj65S9/mZ5//vk8dVmXLl3S4MGD631M1MbH9tVruqO2PJqmd+vWLbVmb47r0NJFgCbr06dPZb17E15p6RJA01TYsTbqP6NaugjQbv62fT1yZEsXAdr08Tb77LMXF7qPP/74HH4POOCANPfcc6dZWX0fA6b9+te/zvdXWWWV9Nprr6WrrrqqwdDdtWvXfKutY8eO+daaTUtCN5WrtR9fdbX+JkxQrwo71qY51qhglfa3rUMFNM+FSj7epreMTQrd0Sx7ttlmyyOH77rrrrnmuPbo5TGQ2nHHHZea04ILLpiWXXbZGssGDhyY/va3vzXr8wAAAEBzaFLoPuGEE6r+f/nll9e7TRGhO0YuH1mrmczbb7+dFltssWZ9HgAAAGix0D169OjUEiLEr7322rl5edSwP/fcc+maa67JNwAAAGgTobulapbXWGONdOedd+bB0c4666w8Xdgll1yS9txzzxYpDwAAADR76G5JW2+9db4BAABAmwjdUaMcI7O99dZbeQC1uB99thsT6999993mKicAAAC0zdC9wQYb5BBdHhK9fB8AAACYydB9ww03pOHDh6evv/469e7dO98HAAAAGjfdM45vtNFG6aGHHprezQEAAKDdm+7QXSqV2v2bBQAAAIWEbgAAAKDA0G3wNAAAACgodO+1116pU6dO03Xr3LnipgAHAACAZjVDyXiTTTZJyyyzTPOWAAAAANqoGQrdgwcPTnvssUdxpQEAAIA2xEBqAAAAUBChGwAAAAoidAMAAEBL9+meNm1aUWUAAACANklNNwAAABRE6AYAAICCCN0AAABQEKEbAAAACiJ0AwAAQEGEbgAAACiI0A0AAAAFEboBAACgIEI3AAAAFEToBgAAgIII3QAAAFAQoRsAAAAKInQDAABAQYRuAAAAKIjQDQAAAAURugEAAKAgQjcAAAAUROgGAACAggjdAAAAUBChGwAAAAoidAMAAEBBhG4AAAAoiNANAAAABRG6AQAAoCBCNwAAABRE6AYAAICCCN0AAABQEKEbAAAACiJ0AwAAQEGEbgAAACiI0A0AAAAFEboBAACgIEI3AAAAFEToBgAAgIII3QAAAFAQoRsAAAAKInQDAABAQYRuAAAAKIjQDQAAAAURugEAAKAgQjcAAAAUROgGAACAggjdAAAAUBChGwAAAAoidAMAAEBBhG4AAAAoiNANAAAABRG6AQAAoCBCNwAAABRE6AYAAICCCN0AAABQEKEbAAAACiJ0AwAAQEGEbgAAAChIRYfu3/zmN6lDhw7p2GOPbemiAAAAQNsJ3c8//3y6+uqr04orrtjSRQEAAIC2E7q//fbbtOeee6bf//73qWfPni1dHAAAAKhX51SBjjjiiLTVVlulTTbZJJ1zzjmNbjtlypR8K5swYUL+OW3atHxrzTqmUksXAZqstR9fbeQaJMTBVlHvQkfHGhWs0v62lTr620blmlYBx9v0lrHiQvett96aRowYkZuXT49zzz03DRs2rM7ysWPHpsmTJ6fWbGBPoZvKNWbMmFRRuumqQoWqsGNt6c5Lt3QRoN38bZvUv39LFwHa9PE2ceLEthe6P/roo3TMMcekhx56KM0+++zT9ZihQ4emIUOG1Kjp7tu3b+rdu3fq1q1bas3eHNehpYsATdanT5/KevcmvNLSJYCmqbBjbdR/RrV0EaDd/G37euTIli4CtOnjbXozaUWF7hdffDFf8Vh11VWrlk2dOjUNHz48XX755bkZeadOnWo8pmvXrvlWW8eOHfOtNZuWhG4qV2s/vupq/U2YoF4VdqxNc6xRwSrtb1uHCmieC5V8vE1vGSsqdG+88cbp1VdfrbFsv/32SwMGDEgnn3xyncANAAAALamiQvc888yTll9++RrL5pprrtSrV686ywEAAKCltf46ewAAAKhQFVXTXZ/HH3+8pYsAAAAA9VLTDQAAAAURugEAAKAgQjcAAAAUROgGAACAggjdAAAAUBChGwAAAAoidAMAAEBBhG4AAAAoiNANAAAABRG6AQAAoCBCNwAAABRE6AYAAICCCN0AAABQEKEbAAAACiJ0AwAAQEGEbgAAACiI0A0AAAAFEboBAACgIEI3AAAAFEToBgAAgIII3QAAAFAQoRsAAAAKInQDAABAQYRuAAAAKIjQDQAAAAURugEAAKAgQjcAAAAUROgGAACAggjdAAAAUBChGwAAAAoidAMAAEBBhG4AAAAoiNANAAAABRG6AQAAoCBCNwAAABRE6AYAAICCCN0AAABQEKEbAAAACiJ0AwAAQEGEbgAAACiI0A0AAAAFEboBAACgIEI3AAAAFEToBgAAgIII3QAAAFAQoRsAAAAKInQDAABAQYRuAAAAKIjQDQAAAAURugEAAKAgQjcAAAAUROgGAACAggjdAAAAUBChGwAAAAoidAMAAEBBhG4AAAAoiNANAAAABRG6AQAAoCBCNwAAABRE6AYAAICCCN0AAABQEKEbAAAACiJ0AwAAQEGEbgAAACiI0A0AAAAFEboBAACgIEI3AAAAFEToBgAAAKE7pXPPPTetscYaaZ555kl9+vRJ22+/fRo5cqQvBwAAAK1SRdV0P/HEE+mII45IzzzzTHrooYfSjz/+mDbddNM0adKkli4aAAAA1NE5VZAHHnigxv0bbrgh13i/+OKLaf3112+xcgEAAEDFh+7axo8fn3/OO++8DW4zZcqUfCubMGFC/jlt2rR8a806plJLFwGarLUfXxXe8Af+T4Udax0da1SwSvvbVurobxuVa1oFHG/TW8aKDd3xAo899ti0zjrrpOWXX77RfuDDhg2rs3zs2LFp8uTJqTUb2FPopnKNGTMmVZRuK7Z0CaBpKuxYW7rz0i1dBGg3f9sm9e/f0kWANn28TZw4sW2H7ujb/dprr6Wnnnqq0e2GDh2ahgwZUqOmu2/fvql3796pW7duqTV7c1yHli4CNFl0/agoE15p6RJA01TYsTbqP6NaugjQbv62fW3AYSpYnwo43mafffa2G7qPPPLIdO+996bhw4enRRZZpNFtu3btmm+1dezYMd9as2lJ6KZytfbjq67W34QJ6lVhx9o0xxoVrNL+tnWogOa5UMnH2/SWsaJCd6lUSkcddVS688470+OPP54WX3zxli4SAAAAtI3QHU3Kb7755nT33Xfnubo///zzvLx79+5pjjnmaOniAQAAQA2tv86+miuvvDKPWL7hhhumBRdcsOp22223tXTRAAAAoPKblwMAAEClqKiabgAAAKgkQjcAAAAUROgGAACAggjdAAAAUBChGwAAAAoidAMAAEBBhG4AAAAoiNANAAAABRG6AQAAoCBCNwAAABRE6AYAAICCCN0AAABQEKEbAAAACiJ0AwAAQEGEbgAAACiI0A0AAAAFEboBAACgIEI3AAAAFEToBgAAgIII3QAAAFAQoRsAAAAKInQDAABAQYRuAAAAKIjQDQAAAAURugEAAKAgQjcAAAAUROgGAACAggjdAAAAUBChGwAAAAoidAMAAEBBhG4AAAAoiNANAAAABRG6AQAAoCBCNwAAABRE6AYAAICCCN0AAABQEKEbAAAACiJ0AwAAQEGEbgAAACiI0A0AAAAFEboBAACgIEI3AAAAFEToBgAAgIII3QAAAFAQoRsAAAAKInQDAABAQYRuAAAAELoBAACgsqjpBgAAgIII3QAAAFAQoRsAAAAKInQDAABAQYRuAAAAKIjQDQAAAAURugEAAKAgQjcAAAAUROgGAACAggjdAAAAUBChGwAAAAoidAMAAEBBhG4AAAAoiNANAAAABRG6AQAAoCBCNwAAABRE6AYAAICCCN0AAABQEKEbAAAACiJ0AwAAQEGEbgAAAChIRYbuK664IvXr1y/NPvvsadCgQem5555r6SIBAABA5Yfu2267LQ0ZMiSdccYZacSIEWmllVZKm222WRozZkxLFw0AAABq6JwqzEUXXZQOOuigtN9+++X7V111VbrvvvvSddddl0455ZQ620+ZMiXfysaPH59/fvPNN2natGmpVZsyqaVLAE0Wx1hFmdKhpUsATVNhx1rp+1JLFwHazd+2iSXHG5Xrmwo43iZMmJB/ln7iWOtQ+qktWpEffvghzTnnnOn2229P22+/fdXywYMH5w/l7rvvrvOYM888Mw0bNmwWlxQAAID24KOPPkqLLLJI26jp/vLLL9PUqVPT/PPPX2N53H/rrbfqfczQoUNzc/SyqN3++uuvU69evVKHDmq22qu4KtW3b998gHTr1q2liwNtmuMNHGvQ1vjbRoj664kTJ6aFFlooNaaiQndTdO3aNd+q69GjR4uVh9YlArfQDY43aEv8bQPHG7NO9+7d29ZAavPNN1/q1KlT+uKLL2osj/sLLLBAi5ULAAAAKj50d+nSJa222mrpkUceqdFcPO6vtdZaLVo2AAAAqPjm5dE/OwZOW3311dOaa66ZLrnkkjRp0qSq0cxhekSXg5h2rnbXA6D5Od5g1nCswazjeGNGVNTo5WWXX355uuCCC9Lnn3+eVl555XTppZemQYMGtXSxAAAAoPJDNwAAAFSCiurTDQAAAJVE6AYAAICCCN0AAABQEKEbAAAACiJ0U9H23Xff1KFDh3TooYfWWXfEEUfkdbFNedvtt9++znaPP/543u6bb76ps27AgAF5SogYKR/auxk53sJHH32U9t9//7TQQgulLl26pMUWWywdc8wx6auvvqp3/7fcckvq1KlT3hfw/4m/P3HcLLXUUmn22WdP888/f1pnnXXSlVdemb777ruqt+lf//pX2nLLLVPPnj3zdiussEK66KKL0tSpU+t9Kw855JB8vP31r3/1VkMznVPW9vHHH+e/f8svv7z3uJ0Tuql4ffv2Tbfeemv6/vvvq5ZNnjw53XzzzWnRRRdt8n6feuqpvM+dd9453Xjjjc1UWmgfx9t7772XVl999TRq1Kgcpt9555101VVXpUceeSSttdZa6euvv66z72uvvTaddNJJefvYJ7R3cRytssoq6cEHH0y//vWv00svvZSefvrpfJzce++96eGHH87b3XnnnWmDDTZIiyyySHrsscfSW2+9lYP6Oeeck3bbbbdUe6KaCOtxHMd+rrvuuhZ6ddD2zylvuOGGtOuuu6YJEyakZ599tplLSyURuql4q666av4leccdd1Qti//HL8c4WWmqCAB77LFH2nvvvZ2UwAweb1ErEFf3IyxEGIj1W2yxRQ4Jn3zySfrv//7vGu/p6NGjc03dKaeckpZZZpka+4f26vDDD0+dO3dOL7zwQj5xHzhwYFpiiSXSdtttl+677760zTbbpEmTJqWDDjoobbvttumaa65JK6+8curXr1868MAD8wXj22+/Pf3lL3+psd+o3V522WXz8TZ8+PDcKgVo3nPKuNh1/fXX5/PIOJ+M80raL6GbNiGasMYvtrK4cr/ffvs1eX8TJ07MJyV77bVX+vnPf57Gjx+fnnzyyWYqLbTt4y1qsf/5z3/mwDDHHHPUeOwCCyyQ9txzz3TbbbfVqH2L/W211Vape/fu+bhzckJ7F90w4qJVXMCaa6656t0mmrvGNrHtCSecUGd9hPK4iBWtR6qL4yuOszje4mJY1MYBzXtOGa1OolXJJptsko+3qEGPi2S0T0I3bUL8Movm4B988EG+/e///m9eVls0x5t77rlr3OKEo7b4xbj00kun5ZZbLvd5i+Z5QgBM3/EWTcojUEetXH1i+bhx49LYsWPz/WnTpuWT/vI+4niL/UftN7RX0SUjjqP+/fvXWD7ffPNV/f06+eST09tvv52XN3S8xdgk5W3Kx+czzzyTfvGLX+T7cdxFwKjdBB3aq+k9p/wpcd4Yf8/iPDL6dEcrFWMotF9CN21C7969cy1ZnLiXa8zixKS2jTbaKL388ss1bn/4wx/qbBdXNav/go3/xy/KqAGH9m56j7efOomP5ufhoYceylf/YxCoEPuKFib6mkJdzz33XP7bFReFp0yZMl3HW/lYC3FcbbbZZlXHbBx30Zrr0Ucf9XbDDPyNa0wMzhvN0mufS6rAab86t3QBoDmbAx155JH5/1dccUW920QTvRgBtvbIktW98cYbuRYgTmyiFqEsRoCNGvDoOwftXWPHWxxj0ez1zTffTDvssEOdx8byOKnp0aNHvh8nIdEkvXpT9Kj9fuWVV9KwYcNSx46uD9P+lI+jkSNH1lgetWWhfLxEq6zycbX22mvX2U8sj37e5b9j0c87RkSPvuJlsTzC+MYbb1zoa4K2dE7ZmBh4LQZgGzRoUI0LY/G3LVqeRLcP2hdnMrQZm2++efrhhx/Sjz/+mK/iN1UEgPXXXz/9+9//rlEjPmTIEFcoYTqOt169euWa6t/97nc1RoANcbJ/0003VU27En1R77777nxBq/rxFqM0RxP06K8K7VH5OLr88ssb7Qcax9+8886b/ud//qfOunvuuSc3Jy8fb/fff39usRXHV/XjLfp8R61cfVNnQns0s+eUcS55/PHH1zjO4rxyvfXW04qrnVLTTZsRfWbiin75/00Rv1z/9Kc/pbPOOqvOnIoxEmzMefr666/nZn3Qnv3U8RZBIWrd4mQlpi1afPHF87Fz4okn5iv8p59+et4ujrcIFzEyc9TqVRfNXuPEJU5+oD2KC1cxJ3dMv3fmmWemFVdcMbf8eP755/O0YKuttlpuwXX11VfnvqMHH3xwrp3r1q1bnp4vjrdonVXuuhHHUzSVXWmllWo8T4xkftxxx+ULYjFwG7R303NOGd0yIkxXF3/P4mLyiBEj8vEUYypUt/vuu+dzzPi7WL21CW2fmm7alDjRiFtTRa1A/LKsr0lsDFITN/1x4KePt2jyGsEgmsJGoF5sscXyoIURuGNQmhgEKkST1jjeagfusNNOO+Vj8ssvv/SW0y4tueSSuVY6Rj8eOnRoDssRwC+77LI8WvnZZ5+dt9t5553zSMkffvhhrkmLi1xxoTimBItpxMIXX3yRpxmL46q2CPJxHPr7BtN/Tvn444/nacSq36JLVBxHcSGrduAOcZyNGTMmtzqhfelQMlwlALPAGWeckVuLxMBpP/vZz7znUJDoSxpzecf820888UQeQwGAliN0AzDLxEiw0STv6KOPNkAaFBy8L7nkktzqpL7abQBmHaEbAAAACqJPNwAAABRE6AYAAICCCN0AAABQEKEbAAAACiJ0AwAAQEGEbgAAACiI0A0AAAAFEboBAACgIEI3AAAApGL8P3TWf1o/rADRAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def benchmark_attention_variants():\n",
    "    \"\"\"\n",
    "    Benchmark inference speed of different attention mechanisms.\n",
    "    \"\"\"\n",
    "    d_model = 512\n",
    "    num_heads = 8\n",
    "    batch_size = 4\n",
    "    seq_len = 128\n",
    "    num_iterations = 100\n",
    "    \n",
    "    # Initialize models\n",
    "    models = {\n",
    "        'MHA': MultiHeadAttention(d_model, num_heads),\n",
    "        'MQA': MultiQueryAttention(d_model, num_heads),\n",
    "        'GQA': GroupedQueryAttention(d_model, num_heads, num_kv_heads=2),\n",
    "        'MLA': MultiHeadLatentAttention(d_model, num_heads, latent_dim=128)\n",
    "    }\n",
    "    \n",
    "    # Set to eval mode\n",
    "    for model in models.values():\n",
    "        model.eval()\n",
    "    \n",
    "    # Benchmark\n",
    "    results = {}\n",
    "    \n",
    "    print(\"=== Attention Mechanism Benchmark ===\")\n",
    "    print(f\"Configuration: batch={batch_size}, seq_len={seq_len}, d_model={d_model}\")\n",
    "    print(f\"Iterations: {num_iterations}\\n\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for name, model in models.items():\n",
    "            x = torch.randn(batch_size, seq_len, d_model)\n",
    "            \n",
    "            # Warmup\n",
    "            for _ in range(10):\n",
    "                _ = model(x)\n",
    "            \n",
    "            # Benchmark\n",
    "            start = time.time()\n",
    "            for _ in range(num_iterations):\n",
    "                _ = model(x)\n",
    "            end = time.time()\n",
    "            \n",
    "            avg_time = (end - start) / num_iterations * 1000  # ms\n",
    "            results[name] = avg_time\n",
    "            \n",
    "            print(f\"{name:8s}: {avg_time:.3f} ms/iteration\")\n",
    "    \n",
    "    # Visualization\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    names = list(results.keys())\n",
    "    times = list(results.values())\n",
    "    \n",
    "    bars = plt.bar(names, times, color=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728'])\n",
    "    plt.ylabel('Time (ms)', fontsize=12)\n",
    "    plt.title('Attention Mechanism Inference Speed', fontsize=14)\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar, time_val in zip(bars, times):\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{time_val:.2f} ms',\n",
    "                ha='center', va='bottom', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "benchmark_attention_variants()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Trade-off Analysis\n",
    "\n",
    "Summarize the trade-offs between different attention mechanisms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Attention Mechanism Comparison ===\n",
      "Method      KV Heads KV Cache Size   Quality   Memory    Speed          Used In\n",
      "   MHA             H         H × d      Best     High Baseline            GPT-3\n",
      "   MQA             1             d      Good      Low   Faster     PaLM, Falcon\n",
      "   GQA G (1 < G < H)         G × d Very Good   Medium     Fast LLaMA 2, Mistral\n",
      "   MLA             H    latent_dim Very Good Very Low Variable      DeepSeek-V2\n",
      "\n",
      "Key Insights:\n",
      "\n",
      "1. **MHA (Multi-Head Attention)**\n",
      "   - Best quality but highest memory\n",
      "   - Used in earlier large models (GPT-3)\n",
      "   - Each head has independent K, V\n",
      "\n",
      "2. **MQA (Multi-Query Attention)**\n",
      "   - Dramatic memory reduction (H× smaller)\n",
      "   - Single shared K, V across all heads\n",
      "   - Slight quality degradation\n",
      "   - Fast inference due to smaller cache\n",
      "\n",
      "3. **GQA (Grouped Query Attention)**\n",
      "   - Best balance: quality vs. memory\n",
      "   - Industry standard for modern LLMs\n",
      "   - LLaMA 2: 32 Q heads, 8 KV heads (4× reduction)\n",
      "   - Mistral: Similar configuration\n",
      "\n",
      "4. **MLA (Multi-Head Latent Attention)**\n",
      "   - Lowest memory via compression\n",
      "   - ~90% KV cache reduction\n",
      "   - Adds compression/decompression overhead\n",
      "   - Cutting-edge research (DeepSeek-V2)\n",
      "\n",
      "\n",
      "=== Practical Recommendations ===\n",
      "\n",
      "Use **GQA** for:\n",
      "  ✓ Production LLM deployments\n",
      "  ✓ Long context windows (32K+ tokens)\n",
      "  ✓ Memory-constrained environments\n",
      "  ✓ High-quality generation requirements\n",
      "\n",
      "Use **MQA** for:\n",
      "  ✓ Maximum speed requirements\n",
      "  ✓ Extreme memory constraints\n",
      "  ✓ Applications where quality loss is acceptable\n",
      "\n",
      "Use **MLA** for:\n",
      "  ✓ Research and experimentation\n",
      "  ✓ Ultra-long contexts (100K+ tokens)\n",
      "  ✓ When willing to trade computation for memory\n",
      "\n",
      "Use **MHA** for:\n",
      "  ✓ Small models where memory isn't critical\n",
      "  ✓ Research baselines\n",
      "  ✓ Maximum quality requirements\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create comprehensive comparison table\n",
    "comparison = {\n",
    "    'Method': ['MHA', 'MQA', 'GQA', 'MLA'],\n",
    "    'KV Heads': ['H', '1', 'G (1 < G < H)', 'H'],\n",
    "    'KV Cache Size': ['H × d', 'd', 'G × d', 'latent_dim'],\n",
    "    'Quality': ['Best', 'Good', 'Very Good', 'Very Good'],\n",
    "    'Memory': ['High', 'Low', 'Medium', 'Very Low'],\n",
    "    'Speed': ['Baseline', 'Faster', 'Fast', 'Variable'],\n",
    "    'Used In': ['GPT-3', 'PaLM, Falcon', 'LLaMA 2, Mistral', 'DeepSeek-V2']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(comparison)\n",
    "\n",
    "print(\"\\n=== Attention Mechanism Comparison ===\")\n",
    "print(df.to_string(index=False))\n",
    "print()\n",
    "\n",
    "print(\"Key Insights:\")\n",
    "print()\n",
    "print(\"1. **MHA (Multi-Head Attention)**\")\n",
    "print(\"   - Best quality but highest memory\")\n",
    "print(\"   - Used in earlier large models (GPT-3)\")\n",
    "print(\"   - Each head has independent K, V\")\n",
    "print()\n",
    "print(\"2. **MQA (Multi-Query Attention)**\")\n",
    "print(\"   - Dramatic memory reduction (H× smaller)\")\n",
    "print(\"   - Single shared K, V across all heads\")\n",
    "print(\"   - Slight quality degradation\")\n",
    "print(\"   - Fast inference due to smaller cache\")\n",
    "print()\n",
    "print(\"3. **GQA (Grouped Query Attention)**\")\n",
    "print(\"   - Best balance: quality vs. memory\")\n",
    "print(\"   - Industry standard for modern LLMs\")\n",
    "print(\"   - LLaMA 2: 32 Q heads, 8 KV heads (4× reduction)\")\n",
    "print(\"   - Mistral: Similar configuration\")\n",
    "print()\n",
    "print(\"4. **MLA (Multi-Head Latent Attention)**\")\n",
    "print(\"   - Lowest memory via compression\")\n",
    "print(\"   - ~90% KV cache reduction\")\n",
    "print(\"   - Adds compression/decompression overhead\")\n",
    "print(\"   - Cutting-edge research (DeepSeek-V2)\")\n",
    "print()\n",
    "\n",
    "# Practical recommendations\n",
    "print(\"\\n=== Practical Recommendations ===\")\n",
    "print()\n",
    "print(\"Use **GQA** for:\")\n",
    "print(\"  ✓ Production LLM deployments\")\n",
    "print(\"  ✓ Long context windows (32K+ tokens)\")\n",
    "print(\"  ✓ Memory-constrained environments\")\n",
    "print(\"  ✓ High-quality generation requirements\")\n",
    "print()\n",
    "print(\"Use **MQA** for:\")\n",
    "print(\"  ✓ Maximum speed requirements\")\n",
    "print(\"  ✓ Extreme memory constraints\")\n",
    "print(\"  ✓ Applications where quality loss is acceptable\")\n",
    "print()\n",
    "print(\"Use **MLA** for:\")\n",
    "print(\"  ✓ Research and experimentation\")\n",
    "print(\"  ✓ Ultra-long contexts (100K+ tokens)\")\n",
    "print(\"  ✓ When willing to trade computation for memory\")\n",
    "print()\n",
    "print(\"Use **MHA** for:\")\n",
    "print(\"  ✓ Small models where memory isn't critical\")\n",
    "print(\"  ✓ Research baselines\")\n",
    "print(\"  ✓ Maximum quality requirements\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary\n",
    "\n",
    "### Key Concepts Covered\n",
    "\n",
    "1. **Multi-Head Attention (MHA)**\n",
    "   - Traditional approach with separate K, V for each head\n",
    "   - High quality but memory-intensive\n",
    "\n",
    "2. **Multi-Query Attention (MQA)**\n",
    "   - Single shared K, V across all heads\n",
    "   - Massive memory savings\n",
    "   - Used in PaLM, Falcon\n",
    "\n",
    "3. **Grouped Query Attention (GQA)**\n",
    "   - Middle ground: groups of queries share K, V\n",
    "   - Industry standard for modern LLMs\n",
    "   - **LLaMA 2, Mistral use GQA**\n",
    "\n",
    "4. **Multi-Head Latent Attention (MLA)**\n",
    "   - Low-rank compression of K, V\n",
    "   - Cutting-edge memory optimization\n",
    "   - Used in DeepSeek-V2\n",
    "\n",
    "5. **KV Cache**\n",
    "   - Essential for efficient autoregressive generation\n",
    "   - Stores K, V from previous tokens\n",
    "   - Reduces O(n²) to O(n) complexity\n",
    "\n",
    "### Memory Savings Example (32-layer model, 2K context)\n",
    "- MHA: ~4 GB KV cache\n",
    "- GQA: ~1 GB KV cache (4× reduction)\n",
    "- MQA: ~128 MB KV cache (32× reduction)\n",
    "- MLA: ~512 MB KV cache (8× reduction)\n",
    "\n",
    "### Production Best Practices\n",
    "1. **Use GQA** for most production deployments\n",
    "2. **Implement KV cache** for all autoregressive models\n",
    "3. **Monitor cache size** as context grows\n",
    "4. **Consider MQA** for edge deployments\n",
    "5. **Explore MLA** for extreme context lengths\n",
    "\n",
    "Understanding these attention mechanisms is critical for:\n",
    "- Building efficient LLM inference systems\n",
    "- Optimizing memory usage\n",
    "- Scaling to longer contexts\n",
    "- Making informed architecture decisions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
