{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mixture of Experts (MoE) Layer in PyTorch\n",
    "\n",
    "This notebook demonstrates the Mixture of Experts architecture, a key technique for scaling neural networks.\n",
    "\n",
    "We'll cover:\n",
    "1. Expert networks - Individual specialized networks\n",
    "2. Gating mechanism - Router that selects experts\n",
    "3. MoE layer implementation from scratch\n",
    "4. Top-K routing strategy\n",
    "5. Practical example with visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Expert Network\n",
    "\n",
    "Each expert is a simple feed-forward network that specializes in processing certain types of inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Expert(nn.Module):\n",
    "    \"\"\"\n",
    "    A single expert network - a simple feed-forward network.\n",
    "    \n",
    "    Args:\n",
    "        input_dim: Input feature dimension\n",
    "        hidden_dim: Hidden layer dimension\n",
    "        output_dim: Output feature dimension\n",
    "        dropout: Dropout probability\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, dropout=0.1):\n",
    "        super(Expert, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.activation = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass through the expert network.\n",
    "        \n",
    "        Args:\n",
    "            x: Input tensor of shape (batch_size, seq_len, input_dim)\n",
    "        \n",
    "        Returns:\n",
    "            Output tensor of shape (batch_size, seq_len, output_dim)\n",
    "        \"\"\"\n",
    "        x = self.fc1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Test the expert network\n",
    "batch_size, seq_len, input_dim = 2, 4, 8\n",
    "hidden_dim, output_dim = 16, 8\n",
    "\n",
    "expert = Expert(input_dim, hidden_dim, output_dim)\n",
    "x = torch.randn(batch_size, seq_len, input_dim)\n",
    "output = expert(x)\n",
    "\n",
    "print(f\"Input shape: {x.shape}\")\n",
    "print(f\"Output shape: {output.shape}\")\n",
    "print(f\"Expert parameters: {sum(p.numel() for p in expert.parameters())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Gating Network\n",
    "\n",
    "The gating network (router) decides which experts should process each input token.\n",
    "It outputs a probability distribution over experts for each token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GatingNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    Gating network that routes inputs to experts.\n",
    "    \n",
    "    Args:\n",
    "        input_dim: Input feature dimension\n",
    "        num_experts: Number of expert networks\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, num_experts):\n",
    "        super(GatingNetwork, self).__init__()\n",
    "        self.gate = nn.Linear(input_dim, num_experts)\n",
    "        self.num_experts = num_experts\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Compute gating weights for each expert.\n",
    "        \n",
    "        Args:\n",
    "            x: Input tensor of shape (batch_size, seq_len, input_dim)\n",
    "        \n",
    "        Returns:\n",
    "            Gate logits of shape (batch_size, seq_len, num_experts)\n",
    "        \"\"\"\n",
    "        # Compute logits for each expert\n",
    "        gate_logits = self.gate(x)  # (batch_size, seq_len, num_experts)\n",
    "        return gate_logits\n",
    "\n",
    "# Test the gating network\n",
    "num_experts = 4\n",
    "gate = GatingNetwork(input_dim, num_experts)\n",
    "gate_logits = gate(x)\n",
    "\n",
    "# Apply softmax to get probabilities\n",
    "gate_probs = F.softmax(gate_logits, dim=-1)\n",
    "\n",
    "print(f\"Gate logits shape: {gate_logits.shape}\")\n",
    "print(f\"Gate probabilities shape: {gate_probs.shape}\")\n",
    "print(f\"\\nExample gate probabilities for first token:\")\n",
    "print(gate_probs[0, 0])  # Probabilities for each expert\n",
    "print(f\"Sum of probabilities: {gate_probs[0, 0].sum().item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Mixture of Experts Layer with Top-K Routing\n",
    "\n",
    "The MoE layer combines multiple expert networks with a gating mechanism.\n",
    "We use Top-K routing where each token is processed by the top-k experts (typically k=2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixtureOfExperts(nn.Module):\n",
    "    \"\"\"\n",
    "    Mixture of Experts layer with Top-K routing.\n",
    "    \n",
    "    Args:\n",
    "        input_dim: Input feature dimension\n",
    "        hidden_dim: Hidden dimension for experts\n",
    "        output_dim: Output feature dimension\n",
    "        num_experts: Number of expert networks\n",
    "        top_k: Number of experts to use per token (typically 2)\n",
    "        dropout: Dropout probability\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_experts=8, top_k=2, dropout=0.1):\n",
    "        super(MixtureOfExperts, self).__init__()\n",
    "        self.num_experts = num_experts\n",
    "        self.top_k = top_k\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        # Create multiple expert networks\n",
    "        self.experts = nn.ModuleList([\n",
    "            Expert(input_dim, hidden_dim, output_dim, dropout)\n",
    "            for _ in range(num_experts)\n",
    "        ])\n",
    "        \n",
    "        # Gating network\n",
    "        self.gate = GatingNetwork(input_dim, num_experts)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass through the MoE layer.\n",
    "        \n",
    "        Args:\n",
    "            x: Input tensor of shape (batch_size, seq_len, input_dim)\n",
    "        \n",
    "        Returns:\n",
    "            output: Output tensor of shape (batch_size, seq_len, output_dim)\n",
    "            aux_loss: Auxiliary load balancing loss\n",
    "            expert_indices: Indices of selected experts for visualization\n",
    "        \"\"\"\n",
    "        batch_size, seq_len, input_dim = x.shape\n",
    "        \n",
    "        # Get gate logits\n",
    "        gate_logits = self.gate(x)  # (batch_size, seq_len, num_experts)\n",
    "        \n",
    "        # Apply softmax to get probabilities\n",
    "        gate_probs = F.softmax(gate_logits, dim=-1)\n",
    "        \n",
    "        # Select top-k experts\n",
    "        top_k_probs, top_k_indices = torch.topk(gate_probs, self.top_k, dim=-1)\n",
    "        # Normalize top-k probabilities\n",
    "        top_k_probs = top_k_probs / top_k_probs.sum(dim=-1, keepdim=True)\n",
    "        \n",
    "        # Initialize output\n",
    "        output = torch.zeros(batch_size, seq_len, self.output_dim, device=x.device)\n",
    "        \n",
    "        # Process each expert\n",
    "        for i, expert in enumerate(self.experts):\n",
    "            # Find which tokens use this expert\n",
    "            expert_mask = (top_k_indices == i).any(dim=-1)  # (batch_size, seq_len)\n",
    "            \n",
    "            if expert_mask.any():\n",
    "                # Get expert output for all inputs (for simplicity)\n",
    "                expert_output = expert(x)  # (batch_size, seq_len, output_dim)\n",
    "                \n",
    "                # Get the weight for this expert for each token\n",
    "                expert_weights = torch.where(\n",
    "                    top_k_indices == i,\n",
    "                    top_k_probs,\n",
    "                    torch.zeros_like(top_k_probs)\n",
    "                ).sum(dim=-1, keepdim=True)  # (batch_size, seq_len, 1)\n",
    "                \n",
    "                # Add weighted expert output\n",
    "                output += expert_weights * expert_output\n",
    "        \n",
    "        # Compute load balancing auxiliary loss\n",
    "        # Encourage uniform distribution of tokens across experts\n",
    "        expert_usage = torch.zeros(self.num_experts, device=x.device)\n",
    "        for i in range(self.num_experts):\n",
    "            expert_usage[i] = (top_k_indices == i).float().mean()\n",
    "        \n",
    "        # Auxiliary loss encourages balanced expert usage\n",
    "        aux_loss = self.num_experts * (expert_usage ** 2).sum()\n",
    "        \n",
    "        return output, aux_loss, top_k_indices\n",
    "\n",
    "# Test the MoE layer\n",
    "moe = MixtureOfExperts(\n",
    "    input_dim=8,\n",
    "    hidden_dim=32,\n",
    "    output_dim=8,\n",
    "    num_experts=4,\n",
    "    top_k=2\n",
    ")\n",
    "\n",
    "x = torch.randn(2, 6, 8)\n",
    "output, aux_loss, expert_indices = moe(x)\n",
    "\n",
    "print(f\"Input shape: {x.shape}\")\n",
    "print(f\"Output shape: {output.shape}\")\n",
    "print(f\"Auxiliary loss: {aux_loss.item():.4f}\")\n",
    "print(f\"Expert indices shape: {expert_indices.shape}\")\n",
    "print(f\"\\nSelected experts for first sequence:\")\n",
    "print(expert_indices[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualize Expert Selection\n",
    "\n",
    "Let's visualize which experts are selected for different tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a longer sequence for better visualization\n",
    "x = torch.randn(1, 20, 8)  # Single batch, 20 tokens\n",
    "output, aux_loss, expert_indices = moe(x)\n",
    "\n",
    "# Create visualization\n",
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "\n",
    "# Create a matrix showing which experts are used for each token\n",
    "expert_matrix = torch.zeros(20, 4)  # seq_len x num_experts\n",
    "for token_idx in range(20):\n",
    "    for k in range(2):  # top_k = 2\n",
    "        expert_idx = expert_indices[0, token_idx, k].item()\n",
    "        expert_matrix[token_idx, expert_idx] += 1\n",
    "\n",
    "# Plot heatmap\n",
    "sns.heatmap(expert_matrix.T, annot=True, fmt='.0f', cmap='YlOrRd', \n",
    "            cbar_kws={'label': 'Usage Count'},\n",
    "            ax=ax, linewidths=0.5)\n",
    "ax.set_xlabel('Token Position')\n",
    "ax.set_ylabel('Expert ID')\n",
    "ax.set_title('Expert Selection Pattern (Top-2 Routing)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print expert usage statistics\n",
    "expert_counts = expert_matrix.sum(dim=0)\n",
    "print(\"\\nExpert usage statistics:\")\n",
    "for i, count in enumerate(expert_counts):\n",
    "    print(f\"Expert {i}: {count.item():.0f} times ({count.item()/40*100:.1f}%)\")\n",
    "print(f\"\\nAuxiliary loss (lower is more balanced): {aux_loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training Example with MoE\n",
    "\n",
    "Let's create a simple classification task to demonstrate how MoE can be trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoEClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    Simple classifier using Mixture of Experts.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, hidden_dim, num_classes, num_experts=4, top_k=2):\n",
    "        super(MoEClassifier, self).__init__()\n",
    "        self.embedding = nn.Linear(input_dim, hidden_dim)\n",
    "        self.moe = MixtureOfExperts(\n",
    "            input_dim=hidden_dim,\n",
    "            hidden_dim=hidden_dim * 2,\n",
    "            output_dim=hidden_dim,\n",
    "            num_experts=num_experts,\n",
    "            top_k=top_k\n",
    "        )\n",
    "        self.classifier = nn.Linear(hidden_dim, num_classes)\n",
    "        self.aux_loss_weight = 0.01  # Weight for auxiliary loss\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, input_dim)\n",
    "        x = self.embedding(x).unsqueeze(1)  # (batch_size, 1, hidden_dim)\n",
    "        x, aux_loss, _ = self.moe(x)\n",
    "        x = x.squeeze(1)  # (batch_size, hidden_dim)\n",
    "        logits = self.classifier(x)  # (batch_size, num_classes)\n",
    "        return logits, aux_loss\n",
    "\n",
    "# Create synthetic dataset\n",
    "torch.manual_seed(42)\n",
    "num_samples = 1000\n",
    "input_dim = 20\n",
    "num_classes = 3\n",
    "\n",
    "# Generate random data\n",
    "X = torch.randn(num_samples, input_dim)\n",
    "y = torch.randint(0, num_classes, (num_samples,))\n",
    "\n",
    "# Create model\n",
    "model = MoEClassifier(\n",
    "    input_dim=input_dim,\n",
    "    hidden_dim=64,\n",
    "    num_classes=num_classes,\n",
    "    num_experts=4,\n",
    "    top_k=2\n",
    ").to(device)\n",
    "\n",
    "# Move data to device\n",
    "X = X.to(device)\n",
    "y = y.to(device)\n",
    "\n",
    "# Training setup\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 50\n",
    "batch_size = 32\n",
    "losses = []\n",
    "aux_losses = []\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0.0\n",
    "    epoch_aux_loss = 0.0\n",
    "    \n",
    "    # Mini-batch training\n",
    "    for i in range(0, num_samples, batch_size):\n",
    "        batch_X = X[i:i+batch_size]\n",
    "        batch_y = y[i:i+batch_size]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        logits, aux_loss = model(batch_X)\n",
    "        \n",
    "        # Compute loss\n",
    "        classification_loss = criterion(logits, batch_y)\n",
    "        total_loss = classification_loss + model.aux_loss_weight * aux_loss\n",
    "        \n",
    "        # Backward pass\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += classification_loss.item()\n",
    "        epoch_aux_loss += aux_loss.item()\n",
    "    \n",
    "    epoch_loss /= (num_samples // batch_size)\n",
    "    epoch_aux_loss /= (num_samples // batch_size)\n",
    "    losses.append(epoch_loss)\n",
    "    aux_losses.append(epoch_aux_loss)\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Aux Loss: {epoch_aux_loss:.4f}\")\n",
    "\n",
    "print(\"\\nTraining completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualize Training Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 4))\n",
    "\n",
    "# Classification loss\n",
    "ax1.plot(losses, label='Classification Loss', color='blue')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Classification Loss During Training')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Auxiliary loss\n",
    "ax2.plot(aux_losses, label='Auxiliary Loss (Load Balancing)', color='orange')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Auxiliary Loss')\n",
    "ax2.set_title('Load Balancing Loss During Training')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Evaluate model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    logits, _ = model(X)\n",
    "    predictions = torch.argmax(logits, dim=1)\n",
    "    accuracy = (predictions == y).float().mean()\n",
    "    print(f\"\\nFinal accuracy: {accuracy.item()*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Compare MoE with Standard Feed-Forward Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StandardClassifier(nn.Module):\n",
    "    \"\"\"Standard classifier without MoE for comparison.\"\"\"\n",
    "    def __init__(self, input_dim, hidden_dim, num_classes):\n",
    "        super(StandardClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim * 2)\n",
    "        self.fc3 = nn.Linear(hidden_dim * 2, hidden_dim)\n",
    "        self.fc4 = nn.Linear(hidden_dim, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "# Create standard model\n",
    "standard_model = StandardClassifier(\n",
    "    input_dim=input_dim,\n",
    "    hidden_dim=64,\n",
    "    num_classes=num_classes\n",
    ").to(device)\n",
    "\n",
    "# Train standard model\n",
    "optimizer_std = torch.optim.Adam(standard_model.parameters(), lr=0.001)\n",
    "standard_losses = []\n",
    "\n",
    "standard_model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0.0\n",
    "    \n",
    "    for i in range(0, num_samples, batch_size):\n",
    "        batch_X = X[i:i+batch_size]\n",
    "        batch_y = y[i:i+batch_size]\n",
    "        \n",
    "        optimizer_std.zero_grad()\n",
    "        logits = standard_model(batch_X)\n",
    "        loss = criterion(logits, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer_std.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    epoch_loss /= (num_samples // batch_size)\n",
    "    standard_losses.append(epoch_loss)\n",
    "\n",
    "print(\"Standard model training completed!\")\n",
    "\n",
    "# Compare models\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(losses, label='MoE Model', linewidth=2)\n",
    "plt.plot(standard_losses, label='Standard Model', linewidth=2)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss: MoE vs Standard Model')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Evaluate both models\n",
    "standard_model.eval()\n",
    "with torch.no_grad():\n",
    "    moe_logits, _ = model(X)\n",
    "    moe_predictions = torch.argmax(moe_logits, dim=1)\n",
    "    moe_accuracy = (moe_predictions == y).float().mean()\n",
    "    \n",
    "    std_logits = standard_model(X)\n",
    "    std_predictions = torch.argmax(std_logits, dim=1)\n",
    "    std_accuracy = (std_predictions == y).float().mean()\n",
    "\n",
    "print(f\"\\nFinal Results:\")\n",
    "print(f\"MoE Model Accuracy: {moe_accuracy.item()*100:.2f}%\")\n",
    "print(f\"Standard Model Accuracy: {std_accuracy.item()*100:.2f}%\")\n",
    "\n",
    "# Compare parameter counts\n",
    "moe_params = sum(p.numel() for p in model.parameters())\n",
    "std_params = sum(p.numel() for p in standard_model.parameters())\n",
    "print(f\"\\nParameter Counts:\")\n",
    "print(f\"MoE Model: {moe_params:,} parameters\")\n",
    "print(f\"Standard Model: {std_params:,} parameters\")\n",
    "print(f\"MoE has {(moe_params/std_params):.2f}x more parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we covered:\n",
    "\n",
    "1. **Expert Networks**: Simple feed-forward networks that specialize in processing certain inputs\n",
    "2. **Gating Network**: Router that decides which experts should process each token\n",
    "3. **Top-K Routing**: Strategy where each token is processed by the top-k experts (typically k=2)\n",
    "4. **Load Balancing**: Auxiliary loss that encourages uniform expert usage\n",
    "5. **Training**: How to train an MoE model with both classification and auxiliary losses\n",
    "\n",
    "### Key Advantages of MoE:\n",
    "- **Scalability**: Can scale to very large models by adding more experts\n",
    "- **Efficiency**: Only a subset of experts is active for each input (sparse activation)\n",
    "- **Specialization**: Different experts can specialize in different patterns\n",
    "- **Conditional Computation**: Computation is adaptive based on input\n",
    "\n",
    "### Practical Considerations:\n",
    "- Load balancing is crucial to prevent expert collapse (all tokens going to one expert)\n",
    "- Top-K routing (typically k=2) balances capacity and efficiency\n",
    "- The auxiliary loss weight needs tuning based on the task\n",
    "- MoE works best with large-scale models and datasets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
